{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ch10 Neural Nets with Keras"
      ],
      "metadata": {
        "id": "kJO41GBEPGEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**인공신경망(artificial neural network)(ANN)**: 뇌에 있는 생물학적 뉴런의 네트워크에서 영감을 받은 머신러닝 모델<br>\n",
        "-> 이는 다재다능함, 강력함, 확장성 좋음"
      ],
      "metadata": {
        "id": "czPZFUOGPkkO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hBzTaKE0O5zm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.1 생물학적 뉴런에서 인공 뉴런까지"
      ],
      "metadata": {
        "id": "q3HFBaXtQK2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "최초의 인경 신경망 구조: 명제 논리를 사용해 동물 뇌의 생물학적 뉴런이 복잡한 계산을 위해 어떻게 상호작용하는지에 대한 간단한 계산 모델 제시"
      ],
      "metadata": {
        "id": "IGoV4gI5QOgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "최근 인공 신경망이 우리 생활에 커다란 영향을 줄 것이라는 근거\n",
        "- 신경망을 훈련하기 위한 데이터가 엄청나게 많아짐\n",
        "- 1990년대 이후 컴퓨터 하드웨어가 크게 발전\n",
        "- 훈련 알고리즘 향상\n",
        "- 일부 인공 신경망의 이론상 제한이 실전에서는 문제가 되지 않는다 밝혀짐\n",
        "- 인공 신경망이 투자와 진보의 선순환에 들어감"
      ],
      "metadata": {
        "id": "2p5Ic6AKQOi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.1 생물학적 뉴런"
      ],
      "metadata": {
        "id": "r1mR6VwGQOlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "생물학적 신경망(biological neural network)(BNN) "
      ],
      "metadata": {
        "id": "e_QTXid7QOnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.2 뉴런을 사용한 논리 연산"
      ],
      "metadata": {
        "id": "ZcHqMQt_QOps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "인공 뉴런(artificial neuron): 생물학적 뉴런에서 착안한 매우 단순한 신경망 모델<br>\n",
        "- 하나 이상의 이진(on/off) 입력과 이진 출력 하나를 가짐\n",
        "- 단순히 입력이 일정 개수만큼 활성화되었을 때 출력을 내보냄\n",
        "- 인공 뉴런의 네트워크를 만들어 어떤 논리 명제도 계산할 수 있다는 것을 증명"
      ],
      "metadata": {
        "id": "XfrTen86QOsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.3 퍼셉트론"
      ],
      "metadata": {
        "id": "kdgHhitZQOuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**퍼셉트론(perceptron)**: 가장 간단한 인공 신경망 구조 중 하나<br>\n",
        "TLU(threshold logic unit) 또는 LTU(linear threshold unit)라고 불리는 조금 다른 형태의 인공 뉴런을 기반으로 함<br>\n",
        "-> 입력과 출력이 이진이 아닌 어떤 숫자이고, 각각의 입력 연결은 가중치와 연관되어 있음\n",
        "\n"
      ],
      "metadata": {
        "id": "KxVuygL7QOw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TLU는 입력의 가중치 합을 계산한 뒤 계산된 합에 **계단 함수**(step function)을 적용하여 결과 출력"
      ],
      "metadata": {
        "id": "UfBdkUiZQOz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**헤비사이드 계단 함수**(Heaviside step function): 퍼셉트론에서 가장 널리 사용되는 계단함수<br>\n",
        "$heaviside(z)= \\begin{cases}0&z<0\\\\ 1&z\\geq 0\\end{cases} , \\  \\  sgn(z)=\\begin{cases}-1&z<0\\\\ 0&z=0\\\\ +1&z>0\\end{cases} $"
      ],
      "metadata": {
        "id": "YfPq_ZhYURhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 TLU는 간단한 선형 이진 분류 문제에 사용할 수 있음<br>\n",
        "i) 입력의 선형 조합을 계산해서 그 결과가 임곗값을 넘으면 양성 클래스 출력<br>\n",
        "ii) 그렇지 않으면 음성 클래스 출력"
      ],
      "metadata": {
        "id": "6S6zzS7uURj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "퍼셉트론은 층이 하나뿐인 TLU로 구성. 각 TLU는 모든 입력에 연결되어 있음<br>\n",
        "**완전 연결 층**(fully connected layer) 또는 **밀집층**(dense layer): 한 층에 있는 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때의 층<br>\n",
        "**입력 뉴런**(input neuron): 퍼셉트론의 입력이 주입되는 곳<br>\n",
        "-> 이 뉴런은 어떤 입력이 주입되든 그냥 출력으로 통과<br>\n",
        "**입력층**(input layer): 모두 입력 뉴런을 구성, 보통 거기에 **편향** 특성이 더해짐<br>\n",
        "=> 전형적으로 이 편향 특성은 항상 1을 출력하는 특별한 종류의 뉴런인 **편향 뉴런**(bias neuron)으로 표현"
      ],
      "metadata": {
        "id": "o6yrePUcURl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 예시: 입력 2개, 출력 3개로 구성된 퍼셉트론<br>\n",
        "        해당 퍼셉트론은 샘플을 세 개의 다른 이진 클래스로 동시에 분류할 수 있으므로 다중 레이블 분류기(multilabel classifier)"
      ],
      "metadata": {
        "id": "LXNyiG30URoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형 대수 이용하여 한 번에 여러 샘플에 대해 인공 뉴런 층 출력 계산<br>\n",
        "`완전 연결층의  출력 계산`<br>\n",
        "$\\  \\  h_{\\mathbf{W} ,b}(\\mathbf{X} )=\\phi (\\mathbf{X} \\mathbf{W} +\\mathbf{b} )$\n",
        "- $\\mathbf{X}$는 입력 특성의 행렬 나타냄. 행: 샘플, 열: 특성\n",
        "- 가중치 행렬 $\\mathbf{W}$는 편향 뉴런을 제외한 모든 연결 가중치 포함. 이 행렬의 행은 입력 뉴런에 해당하고 열은 출력층에 있는 인공 뉴런에 해당.\n",
        "- 편향 벡터 $\\mathbf{b}$는 편향 뉴런과 인공 뉴런 사이의 모든 연결 가중치 포함. 인공 뉴런마다 하나의 편향값 있음\n",
        "- $\\phi$는 활성화 함수(activation function). 인공 뉴런이 TLU인 경우 이 함수는 계단 함수(step function)"
      ],
      "metadata": {
        "id": "Micjr6MdUUxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "퍼셉트론 훈련 방법<br>\n",
        "-> 헤브의 규칙(Hebb's Rule)에 영감 받음 <br>\n",
        "=> 헤브의 규칙: 두 뉴런이 동시에 활성화될 때마다 이들 사이의 연결 가중치가 증가하는 경향이 있다.\n",
        "- 퍼셉트론은 네트워크가 예측할 때 만드는 오차를 반영하도록 조금 변형된 규칙을 사용하여 훈련됨\n",
        "- 퍼셉트론 학습 규칙은 오차가 감소되도록 연결을 강화 (퍼셉트론 한 번에 한 개의 샘플이 주입되면 각 샘플에 대해 예측이 만들어짐)\n",
        "- 잘못된 예측을 하는 모든 출력 뉴런에 대해 올바른 예측을 만들 수 있도록 입력에 연결된 가중치 강화"
      ],
      "metadata": {
        "id": "KUmWs4ehUUzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`퍼셉트론 학습 규칙`<br>\n",
        "$w^{(next \\ step)}_{i,j} \\ = \\ w_{i,j} \\ + \\ \\eta (y_{j}-\\hat{y_{j}})x_{i}$<br>\n",
        "- $w_{i,j}$는 $i$번째 입력 뉴런과 $j$번째 출력 뉴런 사이를 연결하는 가중치\n",
        "- $x_i$는 현재 훈련 샘플의 $i$번째 뉴런의 입력값\n",
        "- $\\hat{y_j}$는 현재 훈련 샘플의 $j$번째 출력 뉴런의 출력값\n",
        "- $y_j$는 현재 훈련 샘플의 $j$번째 출력 뉴런의 타깃값\n",
        "- \\eta는 학습률"
      ],
      "metadata": {
        "id": "ktU58v1ggaSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**퍼셉트론 수렴 이론**(perceptron convergence)<Br>\n",
        ": 각 출력 뉴런의 결정 경계는 선형이므로 퍼셉트론도 복잡한 패턴을 학습하지 못함. 하지만 훈련 샘플이 선형적으로 구분될 수 있다면 이 알고리즘이 정답에 수렴한다는 이론"
      ],
      "metadata": {
        "id": "b6sGsbbxUU1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런은 하나의 TLU 네트워크를 구현한 Perceptron 클래스 제공"
      ],
      "metadata": {
        "id": "ntmgneUJjBH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)]  # 꽃잎 길이, 꽃잎 너비\n",
        "y = (iris.target == 0).astype(np.int)\n",
        "\n",
        "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
        "per_clf.fit(X, y)\n",
        "\n",
        "y_pred = per_clf.predict([[2, 0.5]])"
      ],
      "metadata": {
        "id": "OrQMD8_3gtJp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> 퍼셉트론 학습 알고리즘이 확률적 경사 하강법과 유사함을 볼 수 있음<br>\n",
        "사이킷런의 Perceptron 클래스는 매개변수가 `loss=\"perceptron, learning_rate=\"constant, eta0=1(학습률), penalty=None(규제없음)`인 SGDClassifier와 같음<br>\n",
        "logistic regression classifier와 달리 perceptron은 클래스 확률을 제공하지 않으며 고정된 임곗값을 기준으로 예측을 만듦 => 퍼셉트론보다 로지스틱 회귀가 더 선호"
      ],
      "metadata": {
        "id": "qAnbmHc-UU3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다층 퍼셉트론**(MLP): 퍼셉트론을 여러 개 쌓아올려 일부 제약을 줄인 인공 신경망<br>\n",
        "-> 다층 퍼셉트론은 XOR 문제를 풀 수 있음"
      ],
      "metadata": {
        "id": "Qwl1vGPijgQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.4 다층 퍼셉트론과 역전파"
      ],
      "metadata": {
        "id": "RP2VJMAAUU6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다층 퍼셉트론**(MLP)은 (통과)**입력층**(input layer) 하나와 **은닉층**(hidden layer)이라 불리는 하나 이상의 TLU층과 마지막 **출력층**(output layer)로 구성<br>\n",
        "입력층과 가까운 층을 보통 하위층(lower layer), 출력에 가까운 층을 상위층(upper layer)<br>\n",
        "출력층을 제외하고 모든 층은 편향 뉴런을 포함하며 다음 층과 완전히 연결되어있음"
      ],
      "metadata": {
        "id": "EsIsbx-0UU8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**심층 신경망**(deep neural network)(DNN): 은닉층을 여러 개 쌓아 올린 인공 신경망<br>\n",
        "-> 딥러닝은 심층 신경망을 연구하는 분야이며 조금 더 일반적으로는 연산이 연속하여 길게 연결된 모델 연구"
      ],
      "metadata": {
        "id": "V4pJvaRpUU-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**역전파**(backpropagation) 훈련 알고리즘: 효율적인 기법으로 그레이디언트를 자동으로 계산하는 경사 하강법 <br>\n",
        "=> 네트워크를 두 번(정방향 한 번, 역방향 한 번) 통과하는 것만으로 역전파 알고리즘은 모든 모델 파라미터에 대한 네트워크 오차의 그레이디언트를 계산할 수 있음. 오차를 감소시키기 위해 각 연결 가중치와 편향값이 어떻게 바뀌어야 할지 알 수 있음.\n",
        "\n",
        "1. 한 번에 하나의 미니 배치씩 진행. 전체 훈련 세트를 처리. 이를 여러 번 반복 (여기서 반복을 에포크(epoch)라 함)\n",
        "2. 각 미니배치는 네트워크의 입력층으로 전달되어 첫 번째 은닉층으로 보내짐\n",
        "3. 그다음 (미니 매치에 있는 모든 샘플에 대해) 해당 층에 있는 모든 뉴런의 출력 계산\n",
        "이 결과는 다음 층으로 전달<br>\n",
        "다시 이 층의 출력을 계산하고 결과는 다음 층으로 전달<br>\n",
        "이런 식으로 마지막 층인 출력층의 출력을 계산할 때까지 계속 진행됨<br>\n",
        "=> 이를 **정방향 계산**(forward pass)이라 함\n",
        "4. 그다음 알고리즘이 네트워크의 출력 오차 측정 (손실 함수를 사용하여 기대하는 출력과 네트워크의 실제 출력을 비교하고 오차 측정 값 반환)\n",
        "5. 각 출력 연결이 이 오차에 기여하는 정도를 계산 (연쇄 법칙(chain rule) 적용하면 빠르고 정확히 수행 가능)\n",
        "6. 이 알고리즘은 또 다시 연쇄 법칙을 사용하여 이전 층의 연결 가중치가 이 오차의 기여 정도에 얼마나 기여했는지 측정<Br>\n",
        "이는 입력층에 도달할 때까지 역방향으로 계속됨\n",
        "7. 마지막으로 경사 하강법을 수행하여 방금 계산한 오차 그레이디언트를 사용해 네트워크에 있는 모든 연결 가중치를 수정\n",
        "\n"
      ],
      "metadata": {
        "id": "tw7yQFPCUVBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정리**<br>\n",
        "각 훈련 샘플에 대해 역전파 알고리즘이 먼저 예측을 만들고 (정방향 계산) 오차 측정 -> 역방향으로 각 층을 거치면서 각 연결이 오차에 기여한 정도를 측정 (역방향 계산) -> 이 오차가 감소하도록 가중치 조절 (경사 하강법 단계)"
      ],
      "metadata": {
        "id": "IA9yQD80UVEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주의) 은닉층의 연결 가중치를 랜덤하게 초기화하는 것이 중요"
      ],
      "metadata": {
        "id": "9XAnQD7fX7Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 알고리즘을 잘 작도하기 위해 다층 퍼셉트론 구조에 중요한 변화를 주었음 => **계단 함수를 로지스틱 함수로 바꿈**<br>\n",
        ": 계단 함수는 수평선 뿐이라 계산할 그레이디언트가 없음. 반면 로지스틱 함수는 어디서든지 0이 아닌 그레이디언트가 잘 정의되어있음<Br><br>\n",
        "\n",
        "** 로지스틱 함수 외에 이용할 수 있는 다른 활성화 함수\n",
        "- 하이퍼볼릭 탄젠트 함수 (쌍곡 탄젠트 함수)\n",
        "- ReLU 함수"
      ],
      "metadata": {
        "id": "OunBGg_-oo0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 활성화 함수를 필요한 이유<br>\n",
        "=> 만약 선형 변환을 여러 개 연결하여도 얻는 것은 선형 변환 뿐. 따라서 층 사이에 비선형성을 추가하지 않으면 아무리 층을 많이 쌓아도 하나의 층과 동일해짐."
      ],
      "metadata": {
        "id": "nM0OO5iDoo5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.5 회귀를 위한 다층 퍼셉트론"
      ],
      "metadata": {
        "id": "0BkdukAGX7TT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다층 퍼셉트론은 **회귀 작업**에서 사용 가능<br>\n",
        "값 하나를 예측하는 데에는 출력 뉴런 하나만 필요. 이 때 뉴런의 출력이 예측된 값.<br>\n",
        "**다변량 회귀**(multivariate regression)에서는 동시에 여러 값을 예측하기 때문에 출력 차원마다 출력 뉴런이 하나씩 필요"
      ],
      "metadata": {
        "id": "XY5z1y-cX7VV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 회귀용 다층 퍼셉트론을 만들 때 출력 뉴런에 활성화 함수 사용하지 않고 어떤 범위의 값도 출력되도록 함<br>\n",
        "i) 출력이 항상 양수여야할 때: 출력층에 ReLU 활성화 함수 사용, 또는 softplus 활성화 함수 사용<br>\n",
        "** softplus 함수: $z$가 음수일 때 0에 가까워지고 $z$가 큰 양수일수록 $z$에 가까움<br>\n",
        "ii) 어떤 범위 안의 값을 예측하고 싶을 때: 로지스틱 함수(0 ~ 1) 또는 하이퍼볼릭 탄젠트 함수(-1 ~ 1)를 사용하여 레이블의 스케일을 적절한 범위로 조정"
      ],
      "metadata": {
        "id": "iSJfVE4tqzjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련에 사용하는 손실함수: 전형적으로 평균 제곱 오차<br>\n",
        "if 훈련 세트에 이상치가 많다면 평균 절댓값 오차 사용<bR>\n",
        "혹은 이 둘을 조합한 후버(Huber) 손실 사용 (후버손실: 오차가 임계값보다 작을 때 이차함수, 클 때 선형 함수)"
      ],
      "metadata": {
        "id": "78sozSlarsvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "회귀 MLP의 전형적인 구조\n",
        "\n",
        "|하이퍼파라미터  |일반적인 값  |\n",
        "|------|---|\n",
        "|입력 뉴런 수|특성마다 하나|\n",
        "|은닉층 수 |문제에 따라 다름, 일반적으로 1에서 5 사이|\n",
        "|은닉층의 뉴런 수|문제에 따라 다름, 일반적으로 10에서 100 사이|\n",
        "|출력 뉴런 수|예측 차원마다 하나|\n",
        "|은닉층의 활성화 함수|ReLU (또는 SELU)|\n",
        "|출력층의 활성화 함수|없음, 또는 (출력 양수) ReLU/softplus, 또는 (출력 범위) logistic/tanh 사용|\n",
        "|손실 함수|MSE나 (이상치 있다면)MAE/Huber|"
      ],
      "metadata": {
        "id": "IcjGQzYvX7Xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1.6 분류를 위한 다층 퍼셉트론"
      ],
      "metadata": {
        "id": "d5L2OI4EX7ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다층 퍼셉트론은 **분류** 작업에도 사용 가능<br>\n",
        "다층 퍼셉트론은 다중 레이블 이진 분류(multilabel binary classification) 문제 쉽게 처리 가능<br>\n",
        "손실 함수는 확률 분포를 예측해야 하므로 일반적으로 크로스 엔트로피 손실(cross-entropy loss)(또는 로그 손실(log loss)라고도 부름) 사용하는 것이 좋음"
      ],
      "metadata": {
        "id": "OYVqPMKgX7dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "분류 MLP의 전형적인 구조\n",
        "\n",
        "|하이퍼파라미터  |이진 분류  | 다중 레이블 분류 | 다중 분류|\n",
        "|------|---|---|---|\n",
        "|입력층과 은닉층|회귀와 동일|회귀와 동일|회귀와 동일|\n",
        "|출력 뉴런 수|1개|레이블마다 1개|클래스마다 1개|\n",
        "|출력층의 활성화 함수|로지스틱 함수|로지스틱 함수|소프트맥스 함수|\n",
        "|손실 함수|크로스 엔트로피|크로스 엔트로피|크로스 엔트로피|\n"
      ],
      "metadata": {
        "id": "6AgWzWpIYDtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.2 케라스로 다층 퍼셉트론 구현하기"
      ],
      "metadata": {
        "id": "mDKodNh5YD0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스(Keras)는 모든 종류의 신경망을 손쉽게 만들고 훈련, 평가, 실행할 수 있는 고수준 딥러닝 API"
      ],
      "metadata": {
        "id": "ZavJmqsHYHfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.1 Tensorflow2 설치"
      ],
      "metadata": {
        "id": "RI1wFs-uYHig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** local에서의 설치 실패 => colab 이용"
      ],
      "metadata": {
        "id": "wWTtHWJaYHkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "cb2MsQJ0PjiY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -U tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QPTouHDYlYb",
        "outputId": "8c48f3df-9214-4430-ed5d-a1c70eba502a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.10.26 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSlRTgEnYcy8",
        "outputId": "895f3bde-7446-444f-d4db-42d28efacdc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.2 시퀀셜 API 사용하여 이미지 분류기 만들기"
      ],
      "metadata": {
        "id": "7w-UD0q8YHnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "패션(Fashion) MNIST 데이터셋 사용"
      ],
      "metadata": {
        "id": "O5ricYLCvHBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 케라스 사용하여 데이터셋 적재"
      ],
      "metadata": {
        "id": "B_SXY6zDu78X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIPeBvqIu5N8",
        "outputId": "4e9063d9-7ba9-4716-d3bf-74656d1fc951"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28 x 28 크기의 배열:"
      ],
      "metadata": {
        "id": "IgSDnvj2Y1RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgePSgS-vtTO",
        "outputId": "ddf24500-55f8-4c80-e1a0-6e47e23b9e24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 픽셀의 강도는 바이트(0~255)로 표현:"
      ],
      "metadata": {
        "id": "APoSVNTRv1Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71t1LEBDv2H_",
        "outputId": "11023a4c-b151-4d24-dbca-51548cdb1920"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증 세트 만들기, 경사 하강법으로 신경망을 훈련하기 때문에 입력 특성 스케일 조정"
      ],
      "metadata": {
        "id": "JBtmWqKrY1T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "QB6gEbCYwXtJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST는 레이블에 해당하는 아이템을 나타내기 위해 클래스 이름의 리스트 필요:"
      ],
      "metadata": {
        "id": "otsTxGhwY1WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "tBQVUrocwnZS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[y_train[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NhNMMTpawqBO",
        "outputId": "99b586b6-b8e1-4d73-e6b9-dde13d15ea52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Coat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증 세트는 5,000개의 이미지, 테스트 세트는 10,000개의 이미지:"
      ],
      "metadata": {
        "id": "BG1XqKUWwzxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_valid.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk85JzL_wqDz",
        "outputId": "a663bb4a-8c07-48cc-9918-b4821fadf5bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 데이터셋에 있는 샘플 이미지를 몇 개 출력해보기"
      ],
      "metadata": {
        "id": "_49HpXS2w7K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "6heV3qeuwqGa",
        "outputId": "004b5407-5dfe-4a84-aae8-e9faf56d7875"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x345.6 with 40 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시퀀셜 API 사용하여 모델 만들기"
      ],
      "metadata": {
        "id": "R7Cn5lFUY1Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "두 개의 은닉층으로 이루어진 분류용 다층 퍼셉트론"
      ],
      "metadata": {
        "id": "lA8h-BlWxWMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "5tB8su-JxDe3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 첫 번째 라인: Sequential 모델 생성. 순서대로 연결된 층을 일렬로 쌓아서 구성.\n",
        "- 첫 번째 층을 만들고 모델에 추가<br>\n",
        "Flatten층은 입력 이미지를 1D 배열로 변환. 이 층은 어떤 모델 파라미터도 가지지 않고 간단한 전처리 수행<br>\n",
        "모델의 첫 번째 층이므로 `input_shape` 지정 (여기에는 배치 크기 제외하고 샘플 크기만을 써야함)\n",
        "- 그다음 뉴런 300개 가진 Dense 은닉층 추가. ReLU 활성화 함수 사용. Dense 층마다 각자 가중치 행렬 관리. 이 행렬에는 층의 뉴런과 입력 사이의 모든 연결 가중치가 포함. 또한 (뉴런마다 하나씩 있는) 편향도 벡터로 관리. \n",
        "- 다음 뉴런 100개를 가진 두 번째 Dense 은닉층 추가. ReLU 활성화 함수 사용.\n",
        "- (클래스마다 하나씩) 뉴런 10개를 가진 Dense 출력층 추가. (배타적인 클래스이므로) softmax 활성화 함수 사용."
      ],
      "metadata": {
        "id": "0YO6sfofxERq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "층을 하나씩 추가하지 않고 Sequential 모델을 만들 때 층의 리스트를 전달할 수 있음"
      ],
      "metadata": {
        "id": "PV4FDLXdxFD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "NFnIMnQgxFKp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 summary() 메서드는 모델에 있는 모든 층 출력<br>\n",
        "각 층의 이름, 출력 크기, 파라미터 개수가 출력<br>\n",
        "마지막에 훈련되는 파라미터와 훈련되지 않은 파라미터를 포함하여 전체 파라미터 개수를 출력"
      ],
      "metadata": {
        "id": "ZZDKEsYOxFRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulk53G1jxFXr",
        "outputId": "af85f51f-4ba2-46e8-e5f6-84fda07b2f5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "c87C4R4wzh8P",
        "outputId": "6166ddd0-0131-49c7-ef8e-c57fe4f99979"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aHtGbZize3H",
        "outputId": "382d07c3-b3c3-496e-8504-17d16fd8f9e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.reshaping.flatten.Flatten at 0x7fd73a761790>,\n",
              " <keras.layers.core.dense.Dense at 0x7fd73a761710>,\n",
              " <keras.layers.core.dense.Dense at 0x7fd73a761d90>,\n",
              " <keras.layers.core.dense.Dense at 0x7fd73a761b90>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = model.layers[1]"
      ],
      "metadata": {
        "id": "-HiiPlW7zvT8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wkuaUDqNzvWR",
        "outputId": "922bc002-0712-47d6-fcf4-577299a1a4eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dense_3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer('dense_3') is hidden1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0PuKlX0zvY2",
        "outputId": "ce3e9618-f166-47e2-c074-516486272e0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "층의 모든 파라미터는 `get_weights()` 메서드와 `set_weights()` 메서드를 사용해 접근할 수 있음<br>\n",
        "Dense 층의 경우 연결 가중치와 편향이 모두 포함되어있음"
      ],
      "metadata": {
        "id": "fPtAeRPRzfBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = hidden1.get_weights()"
      ],
      "metadata": {
        "id": "vIGEwluVzfJT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssLfvVcr0Vm4",
        "outputId": "417e78e0-ba56-4b23-d6b2-9694e90cc64e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03679361,  0.02449588,  0.01850631, ..., -0.05402065,\n",
              "        -0.0122071 , -0.06754796],\n",
              "       [ 0.03858304, -0.00970447,  0.0408879 , ...,  0.00285714,\n",
              "        -0.03792779, -0.05684216],\n",
              "       [ 0.03436922,  0.04596813, -0.05064642, ..., -0.03903211,\n",
              "        -0.03777237, -0.0297312 ],\n",
              "       ...,\n",
              "       [-0.02302483, -0.06101149, -0.03124358, ...,  0.02439407,\n",
              "         0.00678386, -0.02166727],\n",
              "       [ 0.03184228, -0.00485849,  0.01837264, ..., -0.02474777,\n",
              "         0.00437061,  0.0317338 ],\n",
              "       [-0.05424199,  0.04803835,  0.05423401, ...,  0.00971263,\n",
              "         0.0488781 , -0.05767034]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA47yAzw0X3s",
        "outputId": "6608d848-7179-4de1-e4d3-080de572eef5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE3PsjIC0X7H",
        "outputId": "89d0cce3-bb10-45ff-f522-490a98958ef1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biases.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yL97Nlu0Y05",
        "outputId": "53991aaa-044c-4f42-db91-bcee3db9eeaf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense 층은 연결 가중치를 무작위로 초기화함. 편향은 0으로 초기화함.<Br>\n",
        "따른 초기화 방법을 사용하고 싶을 때는 층을 만들 때 `kernel_initializer`와 `bias_initializer` 매개변수 설정"
      ],
      "metadata": {
        "id": "rdxBv516zfRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 가중치 행렬의 크기는 입력 크기에 달려 있음. 이 때문에 Sequential 모델에 첫 번째 층을 추가할 때 `input_shape` 매개변수 지정한 것. <br>\n",
        "하지만 입력 크기를 지정하지 않아도 괜찮음. Keras는 모델을 빌드하기 전까지 입력 크기를 기다릴 것. 모델 빌드는 실제 데이터를 주입할 때 또는 `build()` 메서드 호출할 때 일어남.<br>\n",
        "모델이 실제로 빌드되기 전에 층이 가중치를 가지지 않으면 `summary()` 메서드 호출이나 모델 저장 등의 특정 작업을 수행할 수 없음. 따라서 모델을 만들 때 입력 크기를 알고 있다면 지정하는 것이 좋음."
      ],
      "metadata": {
        "id": "V2puPW0601TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 컴파일\n",
        "\n"
      ],
      "metadata": {
        "id": "_2yEd13T01WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 만들고 나서 `compile()` 메서드를 호출하여 사용할 손실함수와 옵티마이저(optimizer)를 지정해야함"
      ],
      "metadata": {
        "id": "Mw2bkxrB1hn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "yvSuK9qszfYP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  레이블이 정수 하나로 이루어져 있고 클래스가 배타적이므로 `\"sparse_categorical_crossentropy\"` 손실 사용 (만약 샘플마다 클래스 별 타깃 확률을 가지고 있다면 `\"categorical_crossentropy\"` 손실 사용<br>\n",
        "(이진 분류나 다중 레이블 이진 분류를 수행한다면 출력층에 `\"softmax\"` 대신 `\"sigmoid\"` 함수 사용하고 `\"binary_crossentropy\"` 손실 사용\n",
        "- optimizer에 `\"sgd\"`를 지정하면 기본 확률적 경사 하강법(stochastic gradient descent)을 사용하여 모델 훈련한다는 의미 => 역전파 알고리즘 수행<br>\n",
        "(sgd optimizer 사용할 때는 학습률을 튜닝하는 것이 중요. 기본값으로 lr=0.01 사용)\n",
        "- 분류기이므로 훈련과 평가 시에 정확도를 측정하기 위해 `\"accuracy\"` 지정"
      ],
      "metadata": {
        "id": "vce2FBWJzffM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 훈련과 평가"
      ],
      "metadata": {
        "id": "a2CHUR964x9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 훈련하려면 간단하게 `fit()` 메서드 호출"
      ],
      "metadata": {
        "id": "AuRJTUKZ41MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5j3q5Sy19X3",
        "outputId": "a754eb54-aeab-438e-ccb8-dd11c1a7a706"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73a749200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73a749200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1698/1719 [============================>.] - ETA: 0s - loss: 0.7275 - accuracy: 0.7573"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd738e059e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd738e059e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7258 - accuracy: 0.7577 - val_loss: 0.5251 - val_accuracy: 0.8188\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4937 - accuracy: 0.8297 - val_loss: 0.4529 - val_accuracy: 0.8476\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4480 - accuracy: 0.8432 - val_loss: 0.4312 - val_accuracy: 0.8510\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4217 - accuracy: 0.8513 - val_loss: 0.3983 - val_accuracy: 0.8644\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4012 - accuracy: 0.8603 - val_loss: 0.3806 - val_accuracy: 0.8726\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3850 - accuracy: 0.8647 - val_loss: 0.3977 - val_accuracy: 0.8608\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3717 - accuracy: 0.8697 - val_loss: 0.3644 - val_accuracy: 0.8730\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3599 - accuracy: 0.8736 - val_loss: 0.3490 - val_accuracy: 0.8798\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3492 - accuracy: 0.8764 - val_loss: 0.3544 - val_accuracy: 0.8762\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3403 - accuracy: 0.8799 - val_loss: 0.3478 - val_accuracy: 0.8762\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3315 - accuracy: 0.8819 - val_loss: 0.3479 - val_accuracy: 0.8784\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3238 - accuracy: 0.8844 - val_loss: 0.3478 - val_accuracy: 0.8782\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3161 - accuracy: 0.8865 - val_loss: 0.3901 - val_accuracy: 0.8578\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3090 - accuracy: 0.8900 - val_loss: 0.3256 - val_accuracy: 0.8854\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3024 - accuracy: 0.8917 - val_loss: 0.3382 - val_accuracy: 0.8788\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2963 - accuracy: 0.8942 - val_loss: 0.3416 - val_accuracy: 0.8804\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2906 - accuracy: 0.8956 - val_loss: 0.3132 - val_accuracy: 0.8898\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2835 - accuracy: 0.8983 - val_loss: 0.3190 - val_accuracy: 0.8860\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2785 - accuracy: 0.8999 - val_loss: 0.3141 - val_accuracy: 0.8856\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2734 - accuracy: 0.9018 - val_loss: 0.3295 - val_accuracy: 0.8806\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2685 - accuracy: 0.9033 - val_loss: 0.3053 - val_accuracy: 0.8906\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2634 - accuracy: 0.9059 - val_loss: 0.3156 - val_accuracy: 0.8872\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2589 - accuracy: 0.9074 - val_loss: 0.3175 - val_accuracy: 0.8876\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2552 - accuracy: 0.9083 - val_loss: 0.3139 - val_accuracy: 0.8878\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2495 - accuracy: 0.9103 - val_loss: 0.2988 - val_accuracy: 0.8932\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2461 - accuracy: 0.9114 - val_loss: 0.2991 - val_accuracy: 0.8930\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2410 - accuracy: 0.9141 - val_loss: 0.2954 - val_accuracy: 0.8954\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2384 - accuracy: 0.9148 - val_loss: 0.3107 - val_accuracy: 0.8890\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2340 - accuracy: 0.9154 - val_loss: 0.2978 - val_accuracy: 0.8904\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2302 - accuracy: 0.9165 - val_loss: 0.2937 - val_accuracy: 0.8956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력 특성(X_train), 타깃 클래스(y_train), 훈련할 에포크 수 전달\n",
        "- 검증 세트 전달 (이는 선택 사항)\n",
        "- Keras는 에포크가 끝날 때마다 검증 세트를 사용해 손실과 추가적인 측정 지표 계산<br> 이 지표는 모델이 얼마나 잘 수행되는지 확인하는데 유용\n",
        "- 훈련 세트 성능이 검증 세트보다 월등히 높다면 아마도 모델이 훈련 세트에 과대적합 되었을 것\n",
        "- 훈련 에포크마다 케라스는 처리한 샘플 개수와 걸린 평균 훈련 시간, 훈련 세트와 검증 세트에 대한 손실과 정확도를 출력\n",
        "- 훈련 손실이 감소하고 있으므로 좋은 신호임!"
      ],
      "metadata": {
        "id": "Wn9vZ3K75BjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i) 어떤 클래스는 많이 등장하고 다른 클래스는 조금 등장하여 훈련 세트가 편중되어 있다면 `fit()` 메서드를 호출할 때 `class_weight` 매개변수 지정하는 것이 좋음. 이는 적게 등장하는 클래스에 높은 가중치, 많이 등장하는 클래스에는 낮은 가중치 부여.<br>\n",
        "ii) 샘플별로 가중치 부여하고 싶다면 `sample_weight` 매개변수 지정"
      ],
      "metadata": {
        "id": "_NcgItGH50Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fit()` 메서드가 반환하는 History 객체에는 훈련 파라미터(`history.params`), 수행된 에프크 리스트(`history.epoch`) 포함.<br>\n",
        "가장 중요한 속성은 에포크가 끝날 때마다 훈련 세트와 검증 세트에 대한 손실과 측정한 지표를 담은 딕셔너리(`history.history`)임!"
      ],
      "metadata": {
        "id": "gEBEFwru6rSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "R_Z14BRezflK",
        "outputId": "ff1056c9-20ba-416f-fd24-c0ae671db02d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련하는 동안 훈련 정확도와 검증 정확도가 꾸준히 상승\n",
        "- 훈련 손실과 검증 손실은 감소\n",
        "- 검증 곡선이 훈련 곡선과 가까움 => 과대적합되지 않았다는 증거\n",
        "- 훈련 손실은 에포크가 진행되는 동안 계산되기 때문에 훈련 곡선을 볼 때는 왼쪽으로 에포크의 절반만큼 이동해서 생각하자!"
      ],
      "metadata": {
        "id": "GsqYKcnwzfrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 모델의 성능이 만족스럽지 않다면 처음으로 되돌아가서 하이퍼파라미터 튜닝해야함.\n",
        "1. 처음 확인할 것은 학습률\n",
        "2. 학습률이 도움되지 않는다면 다른 optimizer 테스트 (항상 다른 하이퍼파라미터를 바꾼 후에는 학습률을 다시 튜닝해야함)\n",
        "3. 여전히 성능이 높지 않으면 층 개수, 층에 있는 뉴런 개수, 은닉층이 사용하는 활성화 함수와 같은 모델의 하이퍼파라미터 튜닝해보기\n",
        "4. `batch_size`와 같은 다른 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "7Q4nJTso7nhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 검증 정확도가 만족스럽다면 테스트 세트로 모델을 평가하여 일반화 오차를 추정해야함. `evaluate()` 메서드 사용."
      ],
      "metadata": {
        "id": "B86iI8mc7nkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nuT22BE8UBc",
        "outputId": "7614ab59-b0ac-4dde-923e-dbc3bcdaadb1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33200815320014954, 0.8812999725341797]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델을 사용해 예측을 만들기"
      ],
      "metadata": {
        "id": "K4-JSkwP7nmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 `predict()` 메서드 사용하여 새로운 샘플에 대해 예측 만들기"
      ],
      "metadata": {
        "id": "lvQ2xGZc7noT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-2EPj_r8gQG",
        "outputId": "8167df6f-dcf4-4160-8f08-8e624a0d1ac9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd73593e830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd73593e830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 350ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99],\n",
              "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfWmEyh88gT8",
        "outputId": "25c38ad4-a5d9-4685-d5fa-2d1ca2ca6d1a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(class_names)[y_pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ieh_K5t8gZq",
        "outputId": "9eecf849-64d5-4ab1-e1ad-5c0b9094e603"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = y_test[:3]\n",
        "y_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPaHMOTh8zBg",
        "outputId": "c4b44861-a0e3-400d-d7a9-a2bfe94bb1fc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[y_test[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "o9uNlLW68zD9",
        "outputId": "440766e5-160d-419e-cf7d-122a08a20ef6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 518.4x172.8 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기"
      ],
      "metadata": {
        "id": "jD_hZhKxY1a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "캘리포니아 주택 가격 데이터셋 사용하여 회귀 신경망으로 이를 해결해보기"
      ],
      "metadata": {
        "id": "jow0JmsqY1dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Kj_ROSzf9Eph"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시퀀셜 API 사용하여 회귀용 MLP를 구축, 훈련, 평가, 예측하는 방법은 분류에서와 유사<br><br>\n",
        "\n",
        "**주된 차이점**\n",
        "- 출력층이 활성화 함수가 없는 하나의 뉴런(하나의 값을 예측하기 때문)을 가진다는 것\n",
        "- 손실 함수로 평균 제곱 오차 사용"
      ],
      "metadata": {
        "id": "KfO82uisY1gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "7q4rAqeh9ez9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]  # 새로운 샘플\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUtmQBRH9ewz",
        "outputId": "831625bc-2417-4071-e053-5a0f8bbe0522"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735953d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735953d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "322/363 [=========================>....] - ETA: 0s - loss: 1.7430"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735ad9320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735ad9320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 1.6419 - val_loss: 0.8560\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.7047 - val_loss: 0.6531\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6345 - val_loss: 0.6099\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.5658\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5355\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5472 - val_loss: 0.5173\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5081\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5130 - val_loss: 0.4799\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4690\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4656\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4482\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4479\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4296\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4233\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4176\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4123\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4071\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4037\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4000\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.3969\n",
            "162/162 [==============================] - 0s 797us/step - loss: 0.4212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735a175f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735a175f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pd.DataFrame(history.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "cqmBGGN7-_Wh",
        "outputId": "1689cd4f-9d08-48f6-b25b-e88049fc88cb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU5Z3v8c+vq7t635tulm52UEFFFgXRGIgbOjMal0lMombRkExiJt5MMvFOZrI4zpLkJvd1kzhJHGOSSWZEoxNFJQEXGDWCAoogILsgawPdTe/7c/84p7ur96LX6tPf9+t1XnWWp6p+XRTfOvXUOc8x5xwiIjLyxQ13ASIiMjAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhC9BrqZPWJmxWb2Tjfbzcx+ZGZ7zWyrmc0b+DJFRKQ30eyh/wpY1sP264AZ/rQc+Gn/yxIRkbPVa6A7514GSnpociPwH86zAcgys3EDVaCIiEQnfgAeYwLwfsTyYX/dsY4NzWw53l48ycnJ84uKivr0hM3NzcTF9f7l4kydo7TOMSkjDuvTM/VNtPUNF9XXP7FeH8R+jaqv73bv3n3KOTemy43OuV4nYDLwTjfbngUuj1h+EVjQ22POnz/f9dXatWujavefGw66SV9/1h0rq+nzc/VFtPUNF9XXP7Fen3OxX6Pq6ztgk+smVwfiI+gIELmrXeivG3Y5qQkAlFTVD3MlIiKDbyACfSVwp3+0yyLgjHOuU3fLcMhOCQNQWq1AF5Hg67UP3cweBZYAeWZ2GPgWkADgnPsZsAq4HtgLVAOfHqxiz1ZOqhfo2kMXkdGg10B3zn2sl+0O+OKAVTSAslO1hy4io0ds/ow7QLKS1YcuIqNHoAM9PhRHZnKCAl1ERoVABzpAbmpYgS4io0LgAz07Naw+dBEZFYIf6ClhSqoahrsMEZFBF/hAz0lNoFRdLiIyCgQ+0LNTw5RU17cMSyAiEliBD/SclDD1jc1U1zcNdykiIoMq8IGerbNFRWSUCHyg56Qo0EVkdAh+oKf5ga5DF0Uk4IIf6C0jLmoPXUQCLvCBrj50ERktAh/oGUnxhOJMZ4uKSOAFPtDNTGeLisioEPhAB50tKiKjw6gIdG8PXYEuIsE2KgI9xz/9X0QkyEZNoKvLRUSCbvQEenU9zc0aoEtEgmtUBHp2SphmB+W1OtJFRIJrVAR6jk4uEpFRYFQEesvZojq5SESCbFQEetuIi+pyEZHgGnmB7hyJtcVndZfs1AQASqrqBqMiEZGYMPIC/eXvs/D1L0DtmajvkpuaCGgPXUSCbeQF+rQriXMNsOPpqO+SHA6RlBCnPnQRCbSRF+gT5lGdPB7efuys7paj0/9FJOBGXqCbcaJgKRx8FcoORX23bJ0tKiIBN/ICHThR8EFvZuvjUd9H47mISNCNyECvTS6AiZfC1sfARXc6f3aK9tBFJNhGZKADcOFH4dRuOPpWVM1zUsOcVqCLSICN3ECf/WEIhb299Chkp4SpqG2koal5kAsTERkeIzfQk7Nh5jLY9gQ09X58eU6aTv8XkWAbuYEOMOc2qD4F+17qtWnL6f+lOrlIRAIqqkA3s2VmtsvM9prZfV1sn2hma83sLTPbambXD3ypXZh+NSTnwNsrem3advq/9tBFJJh6DXQzCwEPAtcBs4CPmdmsDs3+HnjcOTcXuA34t4EutEvxYTj/Zti1qtehAHI04qKIBFw0e+iXAHudc/udc/XACuDGDm0ckOHPZwJHB67EXlx4GzTWwo6VPTZrG3FRgS4iwWSul+O4zexWYJlz7m5/+Q5goXPunog244A1QDaQClzlnNvcxWMtB5YDFBQUzF+xoveukq5UVlaSlpbmLTjHJW98gbrEHN6+6J+6vU9js+PuNdXcPCOBG6aF+/S8faovBqm+/on1+iD2a1R9fbd06dLNzrkFXW50zvU4AbcCD0cs3wH8pEObrwB/489fCuwA4np63Pnz57u+Wrt2bYcV/+rctzKcKz3U4/3O/+Yf3beefqfPzxutTvXFGNXXP7Fen3OxX6Pq6ztgk+smV6PpcjkCFEUsF/rrIt0FPO5/QKwHkoC8KB57YFz4Ee92W89DAWT7F4sWEQmiaAJ9IzDDzKaYWRjvR8+OHdaHgCsBzOw8vEA/OZCF9ihnChQt8kZg7KELKSdVIy6KSHD1GujOuUbgHmA1sBPvaJbtZna/md3gN/sb4LNm9jbwKPAp/6vB0JnzUTi1C45t6bZJjvbQRSTA4qNp5JxbBazqsO6bEfM7gMsGtrSzNPsm+MPXvb308XO7bJKdEmbX8YohLkxEZGiM7DNFIyVnw8xr4Z0noKmxyyY5qQnqchGRwApOoIN3THrVyW6HAshODVPT0ERNfdMQFyYiMviCFegzrvH21Ld2fXx763gu6kcXkQAKVqDHh2H2zfDuc1Bb3mlzdqrOFhWR4ApWoIM3AmNjLezsPBRArgJdRAIseIFeeDHkTO1yBMZsDdAlIgEWvEA38y5P996rcOZwu00aoEtEgix4gQ7+UAAOtv2u3eqM5ATiDF0sWkQCKZiBnjMVihZ2GgogFGdkpYQpUZeLiARQMAMdvG6Xkzvh+NZ2q7NTEnQZOhEJpOAG+uybIC7B20uPkJMa5nRV3TAVJSIyeIIb6Ck53lAA237XbiiA7JSw9tBFJJCCG+jgdbtUFcP+da2rctPUhy4iwRTsQJ95LSRltRsKwNtDr2eoR/cVERlswQ70+ESvL33ns1DnDZs7NjOJxmbHyreH7jrWIiJDIdiBDv5QADWw8xkAbplXyMIpOdz72BYe23homIsTERk4wQ/0ooWQPbl1KIDUxHh+9elLuGLGGL7+5DYeefXA8NYnIjJAgh/oLUMBHHgZznjXtk4Oh3jozvksmz2W+5/dwYNr9w5zkSIi/Rf8QAcv0DsMBZAYH+InH5/LTXMn8P3Vu/juH9/VD6UiMqKNjkDPneaNwri1/VAA8aE4fvCXc/j4won8dN0+vr1yO83NCnURGZlGR6CDt5devAOOb2u3Oi7O+KcPn89nPzCFX68/yNef3EqTQl1ERqDRE+jn3+INBbD1sU6bzIy/u/487r1qBr/bfJgvr3iLhqbmYShSRKTvRk+gp+R41xztMBRACzPj3qtm8nfXn8uzW4/xV7/dTG2DLiYtIiPH6Al0gDkfhcoTcGBdt02WXzGNf/zw+byws5i7fr2RqrrO4S8iEotGV6DPXAZJmZ1GYOzojkWT+MFfzmH9vtPc+cgbnKnRYF4iEvtGV6C3DgWwEt76LTR3309+y/xCHvz4PLYeLuMTD2/QZetEJOaNrkAHuOJrMPZCePqL8PCVcHhTt02vu2AcD92xgD0nKvnoz9dTXF47hIWKiJyd0RfomYVw1xq46SEoP+qF+lNfgIoTXTZfem4+v/z0xRwpq+Evf76ew6XVQ1ywiEh0Rl+ggzccwJyPwpc2wWX3wtbH4cfz4bUfQ2PnrpXF0/L47d0LKa2q5yM/W8/+k5XDULSISM9GZ6C3SEyHq78DX3wdJi2GNX8PP10Me1/o1HTexGweXb6IusZmbv3Zen75pwM6rFFEYsroDvQWudPgE4/Dxx8H1wy/vQUe/RiU7G/XbPb4TB7//KXMLEjjO8/s4IrvrVWwi0jMUKBHmnktfGE9XPUdb3TGBxfCi/dDfVVrk2lj0lix/FIe/ewipo5JVbCLSMxQoHcUnwiX3wv3bILZN8MrP4AfL4BtT7Qb2OvSabndBnt9k8aCEZGhp0DvTsY4uPnn8Jk1kDYGnrwLfnk9HNvarllXwf61l2t45FXtsYvI0Ioq0M1smZntMrO9ZnZfN20+YmY7zGy7mf3XwJY5jCYuhM+uhb/4EZzaBQ99EJ79X1Bd0q5ZZLCPSzXuf3YHH/jeWgW7iAyZXgPdzELAg8B1wCzgY2Y2q0ObGcD/Bi5zzs0G7h2EWodPXAjmfxK+tBkuWQ6bf+0d5rj5V53ONr10Wi73XZLMiuWLmD4mTcEuIkMmmj30S4C9zrn9zrl6YAVwY4c2nwUedM6VAjjnige2zBiRnA3XfRc+/wqMORee+bJ3YtKRzZ2aLpqay6PLFynYRWTIWG+XXTOzW4Flzrm7/eU7gIXOuXsi2jwF7AYuA0LAt51zf+zisZYDywEKCgrmr1ixok9FV1ZWkpaW1qf7DhjnyC/+H6bt+xXh+jKOjbuaA1PuoCGc0WV975Y08fTeenaWNJMRhsXj47lsQgJF6UP/M0ZMvH49UH39F+s1qr6+W7p06Wbn3IKutg1UoD8LNAAfAQqBl4ELnHNl3T3uggUL3KZN3Y+j0pN169axZMmSPt13wNWWw/98Fzb8FJIy4EP/wLrKySxZemWXzTfsP80jrx5g7a5iGpoc543L4JZ5E7jhovHkpycNSckx9fp1QfX1X6zXqPr6zsy6DfT4KO5/BCiKWC7010U6DLzunGsADpjZbmAGsLEP9Y4sSRlw7T/B3Nth1dfgua8wP20aTP85FF3cqfmiqbksmppLSVU9z249ypNvHuGB53byL394lw/MyOOWeYVcPauApITQMPwxIjKSRfN9fyMww8ymmFkYuA1Y2aHNU8ASADPLA2YC+xlN8s+DTz4Dt/yCcH0p/OIqb0THqlNdNs9JDXPnpZN5+ouX8cJXPsjnrpjKruMVfOnRt7j4gRe478mtvHGghN6+QYmItOh1D90512hm9wCr8frHH3HObTez+4FNzrmV/rZrzGwH0AR8zTl3ejALj0lmcMGtvHEihQ80v+Z1w+x8Bj70D7DgM97RMl2Ynp/G3y47l69ecw4b9p/myTePsPLto6zY+D5FOcncNLeQW+ZNYFJu6hD/QSIykkTT5YJzbhWwqsO6b0bMO+Ar/jTqNcWnwJIH4KLb4Q9fg1VfhTd/Ddf/wDuuvRtxccbi6Xksnp7H/TfOZvX24/z3m0f48Ut7+NGLe1gwKZub5xXyZxeOIzM5YQj/IhEZCaIKdOmj/HPhzpWw/few+hvwyDVw0Se8sWLSxvR419TEeG6eV8jN8wo5dqaGp946ypNvHubvfr+Nb6/czuLpuSybPZarZhWQl5Y4RH+QiMQyBfpgM4Pzb4YZ18DL34f1D8KOlTDnNrj4Lq/vvRfjMpP5qyXT+PwHp7LtyBme3nKU1duPc9+ubcT9fhsLJuVwzewCrp09lqKclCH4o0QkFinQh0pimjf2+kWfgFf+j9cFs/HfYdLlcPFn4Ny/gPhwjw9hZlxYmMWFhVn8/Z+dx45j5azefoI124/zwHM7eeC5ncwen8G1s8ey7PyxzMhPw8yG6A8UkeGmQB9qY2bCzQ/Btf/sXah60yPwxGcgNR/m3QnzPwVZRb0+jJkxe3wms8dn8pWrZ/LeqSpWbz/O6u3H+eHzu/nh87uZkpfKNbMLWDZ7LHMKs4iLU7iLBJkCfbik5nnD9C7+a9j3Imx82Buq99UfwszrvL32qR+CuOjOJJ2cl8rnPjiNz31wGsXltazZcYLV24/zi1cO8PP/2U9BRiLXzBrLtbPH0tisQyFFgkiBPtzi4mDG1d5UetAb8OvN/4Bdz0H2FO9wx7m3Q0pO1A+Zn5HE7YsmcfuiSZypbuClXSdY/c4Jnth8mN9sOEhKPFx2eJN/klMO543N0N67SAAo0GNJ9iS46luw5D7v+PWND8Pz/wAvPQDn3+L9iDphvvdDa5QyUxK4aW4hN80tpKa+iVf2nOS3a99mz4kKnt9xwmuTnMDCKTmtZ7GeOzZdAS8yAinQY1F8Ilxwqzed2A4bfwFbH4O3/wvGzfH62add6X0AnIXkcIhrZo8lfPJdlixZwtGyGl4/cJoN+0rYcOA0a/yAz0ppH/DnFCjgRUYCBXqsK5gNf/5D7wiZrY/Bxke8C2wAZBbBpMtg8mXebc7Us9p7H5+V3Lr3DnCkrIbX959mw/7TrN9/mtXbvYDPTklg4RSve2bRtFxm5ivgRWKRAn2kSEyHi++GBXdB8Q54709w8FXY+wJs9YchTh8XEfCXQ96Mswr4CVnJrSczARwureb1/SWtAf/H7ccBL+AvKspiTlEWF/lTVkrPh1yKyOBToI80Zt5ee8FsWLjcu3D1qd3w3qtw8E/e7TtPeG1T82HSYph8uRf0Y86N+qgZgMLsFArnp3DLfC/g3y+p5vUDJbxx4DRb3i9j3e6TrdfNnpyb0hruF03M5rxx6STGa8RIkaGkQB/pzGDMOd508V1ewJfsh/de8ffi/wQ7nvLaJufApMUUNuTDrhrImuh12yRlRPVURTkpFOWkcKsf8BW1DWw7coYt75fx9vtlrN9/mqe2HAUgHIrjvPEZzC3KYk5RJhcVZTM5N0UnOokMIgV60JhB7jRvmv8pL+BL3/P33r1umullh2DfI233Sc72wj1rImRNipjvOfDTkxJYPC2PxdPyWtcdO1PDlkNlbDlcxpZDZTy+6X1+9dp7gHc0TUs3zezxGcwal0FhdrJCXmSAKNCDzgxypnjT3NsB+NOap7hsVhGUHYSyQ23Tyd2w5wVorGn/GB0DP2cqnPcXkJbf6enGZSYz7oJkrrtgHABNzY49xRVeyL/vTT95aQ8t5zZlJMVz3rgMZo/PZJYf8jrxSaRvFOijUEM4Cwrne1NHznkX5Sg71DnwT+2BvS9CQzX84W9hxrXeh8SMqyHU9XC+oTjj3LEZnDs2g9sumQhATX0Tu05UsP3oGXYcLWfHsXIefeMQNf7Fs0MG52x7pTXgZ433powkDRks0hMFurRn5g3tmzam+8A/ucs7Jn7Lo94Zran53uiRc2/3+vJ7kRwOtf6A2qKp2XHgVBU7jpXzxw3vUJmQyLpdxTyx+XBrm6KcZGaNy+C8cRnMyE9nWn4qk3NTdbk+EZ8CXc6OmTfO+9X3e1di2vuCN8jYhn+D134EhZd4wT77pqh/bAVvT356fhrT89PIKN3NkiWXAFBcUcv2o+Wte/I7j5azZseJ1qNr4sz7sXb6mDSm5af5t6lMH5NOZor26GV0UaBL34US4JzrvKmy2Dvx6a3fwjN/DX+8D2Z9GOZ+wjtkso8/fOanJ5F/ThJLz2nrr6+pb2LfyUpvKq5k38kq9hZX8sqeU9Q3Nbe2y0sLM61d0HsfGOMyknRilASSAl0GRlo+LP4SXHoPHNkMb/0Gtj3pdc1kT/GCfc7HIXNCv58qORzi/AmZnD8hs936pmbH4dJq9hZ7Yb/XD/vnth7jTE1D2/0TQkz0D8GcmJPCxJxkJuZ684XZKerCkRFLgS4DywwKF3jTtf8CO1d6e+0vPQBr/xmmfQguvM0bkyZ7cq8X9TgboThjUm4qk3JTufK8gtb1zjlOV9W3Bv2+4ireL63m/ZJqXtt3iur6pnaPk5+e6Ad9ROj7gT9Gl/uTGKZAl8ETTvF+LJ1zG5QcgC3/5U3/fbe33eK8wyBzp3vDFOROg9zpJNaehObmszqrtSdmRl5aInlpiSyamttuW0vYHyrxAv7Q6WoOlXjThv2n+f2WI6399QCJ8XHkJDpm7n+DCdnJTMhKpjDbmyZkpZCfnqjuHBk2CnQZGjlT4EPf8IYGPrbFOwTy9N626eCfvMMhgUsBNn2p7QSp3On+5If+WYwN35vIsJ83MbvT9rrGJo6U1vB+aU1r6G/edZDTVXVsPVxGaXVDu/YJIWNcphf0E1qD3p/PSmFsZhLh+IH5oBLpSIEuQysu5I3pPqHDIZHOQcUxOL2XXetXcU5uyAv6E9vh3eegubGtbVImJGZ63wDCqZCQAuE0bz7szyf42yKnBP82KdM7vLKbY+cjJcaHmDomjalj0lrXrUs5wZIlHwCgqq6Ro2U1HC6r4XBpDUdKazhSVsOR0mpe2XOS4oq6dnv4ZlCQnkRBRiJj/Nv89CTyMxLJT0+kICOJ/PREctMSCWlPX86SAl1igxlkjIeM8Rw72Mw5S5a0bWtq8K7m1LI3X3YQ6iqhvtLbq6+vgvIj3m3Lcn0luOZun474ZK+ff9JimLgICi/2RrQ8S6mJ8cwoSGdGQdf3rWts4lhZrR/yXvAfKa2huKKWw6XVbD5Y0mkvH7zDMXPTEtsCP90L/Hw/8Meke98qxqQn6kdcaaVAl9gXSoC86d4ULeegsc4P+So/5Ku9oK86CYc3wqH18PL3veC3EIy9ACZeCpMu9W67GNrgbCXGh5icl8rkvNRu29Q3NnOyso7i8lqKKyJv6yiuqOVEeS3bjpzhVGX7vf0W6UnxjElLJC89kTF+yFecrOdE6qF2wZ+bmqjunoBToEswmUFCkjeR23n7Bbd6t7XlbeF+aANs/iW8/lNvW8609gF/lhcQiVY4Ps7rZ89K7rFdY1Mzp6vqKS6v41RlHScr6jgZcXuqoo6dx8t5eU8dFbWNPLlnW6fHyEpJYExaIjmp4dYpNzVMdut8ItmpCa23GgJ5ZFGgy+iWlAHTr/QmgMZ6OPY2HHrNC/hdz8GW33rbUvNh4iKK6rLhjT1+uJt3a3Ft8x1vO24LJcD4uWd9CcH4UBwFGUkUZCT12nbNi2uZNW8hpyrrvcCvaPsQOFVZx+mqevYUV1JaVU9pdT3djYeWlhjfLvxbPgCyUsJkpSSQlZzQOp/t36oLaPgo0EUixYeh6GJvuuzL3uGTp3a3BfzB9Uw7cwj2D8BzZU70Lj7SMp1lwPckHDLvAiXZKb22bWp2nKlpoKSqjpIq7/Z0VT2lVfWcrqqnxJ9OlNey81g5p6vqqW/s/veJpIQ4spL9wE9JICs5THZqApnJYbL9dYeON5Kw9xQZSQlkJMeTkZRAelI88SF1CfWHAl2kJ3Fx3tg1+efCgs8A8Orzz3D5pQu9fnqcd+ua2+Y73rb8ONuyrr4S3n/DuwjJ7j96Z9OCH/CXtQV81qRB6eLpKBRnrXvf0XDOUdvQTFlNPaVVDZTV1FNW3UBZdQOl1fWcqWmgrLqe0uoGzlQ3sO9kJWWHvHUNTW1fBR7c8nqnx04Nh8hITugU9J3XJZCWFO9tS4onLdFrlxIOjerx9RXoImepMSG9/z+Yjp8LCz/nfQM4+a536cD3XoE9a+DtR702rRcBb9mDnzwkAd8bMyM5HCI5nMy4zJ77/SM556iub6KspoGXXlnPzNlzKK9tpLymgfLaBsprGv3btuXj5bXsLvbmK2obuu0aahFnXjdRuv9B4E3efMf1aYn+lBRPuv+BkOavd139+jwCKNBFhlNcHBTM8qaFy/0unl1tAR95EfCMQm8PfuKlkFUEqWO8KSVvQIdQGCxmRmpiPKmJ8RSlx7Fwahc/VvegudlRVd9Iea0X7pW1jVTUNlJR5y1X1Db66xr8dd58cUUt+042traPHMCtOyGDjFfW+AGfQHpiW9inJcWTGg6RHPZuUyLmk8MhUhPjSU7wblP87Snh+CE5r0CBLhJL4uIg/zxvuuSzbePPv/eKF/L7XvJGtewoMRNS8/yQz2PmmQZofrV1uV34p+R4J3iNMHFx5u9hJwDRfzPoqLahiSo/8Csjbivr/A+JukZ27N5PTsH41uXK2kZOVtRx4FQVFbUNVNc3dRoDqDeJ8XGt4f61a8/hw3P7P1BdRwp0kVjWMv58/rltAV/6njdccdVJfzoF1afalkv2k1d6BI4/383JVeZdVjAlN2LK6bDcYX1SZkx09wyEpIQQSQkhcnsYaG0dh1my5PweH6e52VHb6AV7dV0T1Q2NVNU1UVPfRFV9Y7vb6sh1dU3kZwzOIG8KdJGRJPIasT14bd06llxxBdSUtgV99Skv/KtOQvXptqnsIBx905tvqu/6AePiITki9JOzvLBPzo6YOiyn5EBC3/ekY11cnJESjiclHA9pvbcfCgp0kaCKi4PUXG/i3N7bO/8InNawL2kf/JHrSvZ7495Xl0BTXfePGZ/UIfCzIDmbqacqIfRmxLas9h8G4bTAfCMYSlEFupktA/4fEAIeds79azftbgGeAC52zm0asCpFZPCZeePZJKZ7R9REq77a+yZQUwo1JRHzpV7gRy6X7IfqEgqrTsP7v+/+MePi28I9qUPYJ2d5NYZTIwZla5nSI+bTIDS69ll7/WvNLAQ8CFwNHAY2mtlK59yODu3SgS8DnQ8uFZHgCqd401lcjerldetYctnC9mFfUwo1ZV2sK/VG4ize6c3XV0RfWyixc/AnpkUsp0Ust8ynknP6ALyX0HlbQkpMf3OI5uPrEmCvc24/gJmtAG4EdnRo94/Ad4GvDWiFIhJMCcnelDH+7O7X1OAPtlbVNrJml/Pdbav0fkuoq/Dm6yo7dRtdCNB5KBzA/IBPaRuiOSE5Yj6lbVvrfGrndWPOPfu/OwrW2wH0ZnYrsMw5d7e/fAew0Dl3T0SbecA3nHO3mNk64KtddbmY2XJgOUBBQcH8FStW9KnoyspK0tJi5FeILqi+/lF9/RfrNcZafdbcSKipllBTDaGmGuorSkgP025dy3x8Yw1xzbWEmuoINdV1MV9LqKmeuOZa4lzXhzbunvF5jk64rk+1Ll26dLNzbkFX2/rdwWRmccAPgU/11tY59xDwEMCCBQvcksgxr8/CunXr6Ot9h4Lq6x/V13+xXuNIqG/OQNTXWO8N39xQ4/3W4M/PzJrEzIxx/X/8DqIJ9CNAUcRyob+uRTpwPrDOH0NhLLDSzG7QD6MiMqrFh70pufPlDQdDNEObbQRmmNkUMwsDtwErWzY658445/Kcc5Odc5OBDYDCXERkiPUa6M65RuAeYDWwE3jcObfdzO43sxsGu0AREYlOVH3ozrlVwKoO677ZTdsl/S9LRETOlkaTFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQEQV6Ga2zMx2mdleM7uvi+1fMbMdZrbVzF40s0kDX6qIiPSk10A3sxDwIHAdMAv4mJnN6tDsLWCBc989nDEAAAeSSURBVO5C4AngewNdqIiI9CyaPfRLgL3Ouf3OuXpgBXBjZAPn3FrnXLW/uAEoHNgyRUSkN+ac67mB2a3AMufc3f7yHcBC59w93bT/CXDcOfdAF9uWA8sBCgoK5q9YsaJPRVdWVpKWltan+w4F1dc/qq//Yr1G1dd3S5cu3eycW9DlRudcjxNwK/BwxPIdwE+6aXs73h56Ym+PO3/+fNdXa9eu7fN9h4Lq6x/V13+xXqPq6ztgk+smV+Oj+EA4AhRFLBf669oxs6uAbwAfdM7VRftpIyIiAyOaPvSNwAwzm2JmYeA2YGVkAzObC/wcuME5VzzwZYqISG96DXTnXCNwD7Aa2Ak87pzbbmb3m9kNfrPvA2nA78xsi5mt7ObhRERkkETT5YJzbhWwqsO6b0bMXzXAdYmIyFnSmaIiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEBEFehmtszMdpnZXjO7r4vtiWb2mL/9dTObPNCFiohIz3oNdDMLAQ8C1wGzgI+Z2awOze4CSp1z04H/C3x3oAsVEZGeRbOHfgmw1zm33zlXD6wAbuzQ5kbg1/78E8CVZmYDV6aIiPQmPoo2E4D3I5YPAwu7a+OcazSzM0AucCqykZktB5b7i5VmtqsvRQN5HR87xqi+/lF9/RfrNaq+vpvU3YZoAn3AOOceAh7q7+OY2Sbn3IIBKGlQqL7+UX39F+s1qr7BEU2XyxGgKGK50F/XZRsziwcygdMDUaCIiEQnmkDfCMwwsylmFgZuA1Z2aLMS+KQ/fyvwknPODVyZIiLSm167XPw+8XuA1UAIeMQ5t93M7gc2OedWAr8AfmNme4ESvNAfTP3uthlkqq9/VF//xXqNqm8QmHakRUSCQWeKiogEhAJdRCQgYjrQY3nIATMrMrO1ZrbDzLab2Ze7aLPEzM6Y2RZ/+uZQ1ec//3tmts1/7k1dbDcz+5H/+m01s3lDWNs5Ea/LFjMrN7N7O7QZ8tfPzB4xs2IzeydiXY6ZPW9me/zb7G7u+0m/zR4z+2RXbQahtu+b2bv+v9/vzSyrm/v2+F4Y5Bq/bWZHIv4dr+/mvj3+fx/E+h6LqO09M9vSzX2H5DXsF+dcTE54P8DuA6YCYeBtYFaHNl8AfubP3wY8NoT1jQPm+fPpwO4u6lsCPDuMr+F7QF4P268H/gAYsAh4fRj/rY8Dk4b79QOuAOYB70Ss+x5wnz9/H/DdLu6XA+z3b7P9+ewhqO0aIN6f/25XtUXzXhjkGr8NfDWK90CP/98Hq74O238AfHM4X8P+TLG8hx7TQw44544559705yuAnXhnzI4kNwL/4TwbgCwzGzcMdVwJ7HPOHRyG527HOfcy3pFakSLfZ78GPtzFXa8FnnfOlTjnSoHngWWDXZtzbo1zrtFf3IB3nsiw6eb1i0Y0/9/7raf6/Oz4CPDoQD/vUInlQO9qyIGOgdluyAGgZciBIeV39cwFXu9i86Vm9raZ/cHMZg9pYeCANWa22R92oaNoXuOhcBvd/ycaztevRYFz7pg/fxwo6KJNLLyWn8H7xtWV3t4Lg+0ev1vokW66rGLh9fsAcMI5t6eb7cP9GvYqlgN9RDCzNOBJ4F7nXHmHzW/idSPMAX4MPDXE5V3unJuHN1LmF83siiF+/l75J6vdAPyui83D/fp14rzv3jF3rK+ZfQNoBP6zmybD+V74KTANuAg4htetEYs+Rs975zH//ymWAz3mhxwwswS8MP9P59x/d9zunCt3zlX686uABDPLG6r6nHNH/Nti4Pd4X2sjRfMaD7brgDedcyc6bhju1y/CiZauKP+2uIs2w/ZamtmngD8HPuF/4HQSxXth0DjnTjjnmpxzzcC/d/Pcw/pe9PPjZuCx7toM52sYrVgO9JgecsDvb/sFsNM598Nu2oxt6dM3s0vwXu8h+cAxs1QzS2+Zx/vx7J0OzVYCd/pHuywCzkR0LQyVbveKhvP16yDyffZJ4Oku2qwGrjGzbL9L4Rp/3aAys2XA3wI3OOequ2kTzXthMGuM/F3mpm6eO5r/74PpKuBd59zhrjYO92sYteH+VbanCe8ojN14v35/w193P96bFyAJ76v6XuANYOoQ1nY53lfvrcAWf7oe+Dzweb/NPcB2vF/sNwCLh7C+qf7zvu3X0PL6RdZneBcv2QdsAxYM8b9vKl5AZ0asG9bXD+/D5RjQgNePexfe7zIvAnuAF4Acv+0C4OGI+37Gfy/uBT49RLXtxet7bnkPthz1NR5Y1dN7YQhfv9/476+teCE9rmON/nKn/+9DUZ+//lct77uItsPyGvZn0qn/IiIBEctdLiIichYU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgPj/MI1hEtpXvkQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential 모델이 널리 사용되지만 입력과 출력이 여러 개거나 더 복잡한 네트워크 토폴로지를 갖는 신경망을 만들어야할 때는 Keras의 함수형(functional) API 사용"
      ],
      "metadata": {
        "id": "b8zNTWh2Y1iA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.4 함수형 API를 사용해 복잡한 모델 만들기"
      ],
      "metadata": {
        "id": "XBW5EaqeY1kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순차적이지 않은 신경망의 예: 와이드&딥 신경망<Br>\n",
        "이는 입력의 일부 또는 전체가 출력층에 바로 연결. 이 구조를 사용하면 신경망이 (깊게 쌓은 층을 사용한) 복잡한 패턴과 (짧은 경로를 사용한) 간단한 규칙 모두를 학습 가능<br>\n",
        "(이와 대조적으로 일반적인 MLP는 네트워크에 있는 층 전체에 모든 데이터를 통과시킴)"
      ],
      "metadata": {
        "id": "hGLi3D1mY1m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "metadata": {
        "id": "fpxziQLoZH6V"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 먼저 Input 객체 만들기. 이 객체는 shape와 dtype 포함하여 모델의 입력 정의. 한 모델은 여러 개의 입력을 가질 수 있음.\n",
        "- 30개의 뉴런과 ReLU 활성화 함수를 가진 Dense 층 만듦. 이 층은 만들어지자마자 입력과 함께 함수처럼 호출됨.(이러한 이유로 함수형 API라 부름)(케라스에 층이 연결될 방법을 알려주었을 뿐 아직 어떤 데이터도 처리하지 않았음)\n",
        "- 두 번째 은닉층을 만들고 함수처럼 호출\n",
        "- Concatenate 층을 만들고 또 다시 함수처럼 호출하여 두 번째 은닉층의 출력과 입력을 연결\n",
        "- 하나의 뉴런과 활성화 함수가 없는 출력층을 만들고 Concatenate 층이 만든 결과를 사용하여 호출\n",
        "- 마지막으로 사용할 입력과 출력을 지정하여 케라스 Model 만듦"
      ],
      "metadata": {
        "id": "Om8zU3CH_E_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnvqhtqdZH-y",
        "outputId": "d5b89c32-40d1-4692-d744-201521482c9e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 30)           930         ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
            "                                                                  'dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 1)            39          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGNMGRKeAJXq",
        "outputId": "31337150-0cdd-4d94-d3e0-1d58cebfbb39"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735e0cb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735e0cb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "334/363 [==========================>...] - ETA: 0s - loss: 1.9738"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735bf57a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735bf57a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 1.8772 - val_loss: 0.6913\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6501 - val_loss: 0.9454\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6622\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5654 - val_loss: 0.5284\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5414 - val_loss: 0.5004\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5181 - val_loss: 0.5894\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5035 - val_loss: 0.5889\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4904 - val_loss: 0.4690\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4769 - val_loss: 0.5305\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.5466\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4601 - val_loss: 0.4996\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.7264\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4205\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4467\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4367 - val_loss: 0.4167\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4486\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4021\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.3991\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4348\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.3965\n",
            "162/162 [==============================] - 0s 864us/step - loss: 0.4164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735b8d440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735b8d440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 일부 특성은 짧은 경로로 전달하고 다른 특성들은 깊은 경로로 전달하고 싶다면 여러 입력을 사용하는 방법이 있음"
      ],
      "metadata": {
        "id": "IhDMNr3d_-1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "metadata": {
        "id": "I9Gg5f5_ZIA0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델이 복잡해지면 가장 중요한 층에는 이름을 붙이는 것이 좋음\n",
        "- 모델 만들 때 `inputs=[input_A, input_B]`와 같이 지정<br>\n",
        " `fit()` 메서드를 호출할 때 하나의 입력 행렬 `X_train`을 전달하는 것이 아니라 입력마다 하나씩 행렬의 튜플 `(X_train_A, X_train_B)`을 전달해야함<br>\n",
        " `X_valid`에도 동일하게 적용"
      ],
      "metadata": {
        "id": "eg_rWz9uAcF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvc1gIEaAPMA",
        "outputId": "3bfb6168-1678-4b46-bca9-3ba2d29c6dec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735e19c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735e19c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - ETA: 0s - loss: 2.0090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e5da70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e5da70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.0090 - val_loss: 0.9850\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.7896 - val_loss: 0.7180\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6514 - val_loss: 0.6402\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.5778\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5671 - val_loss: 0.5449\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.5190\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5011\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5073 - val_loss: 0.4808\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4945 - val_loss: 0.4661\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4553\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4758 - val_loss: 0.4457\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4687 - val_loss: 0.4377\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4627 - val_loss: 0.4322\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4273\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4536 - val_loss: 0.4230\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4185\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4466 - val_loss: 0.4177\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4441 - val_loss: 0.4169\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4409 - val_loss: 0.4134\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4386 - val_loss: 0.4224\n",
            "162/162 [==============================] - 0s 888us/step - loss: 0.4297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd740225290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd740225290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 47ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 개의 출력이 필요한 경우\n",
        "- 회귀 작업과 분류 작업을 함께 사용하는 경우\n",
        "- 다중 작업 분류(multitask classification) (동일한 데이터에서 독립적인 여러 작업을 수행할 때_\n",
        "- 규제 기법으로 사용하는 경우"
      ],
      "metadata": {
        "id": "GNqcH0piZIJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "규제를 위한 보조 출력 추가하기"
      ],
      "metadata": {
        "id": "OmkQ_-umBcIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
        "model = keras.models.Model(inputs=[input_A, input_B],\n",
        "                           outputs=[output, aux_output])"
      ],
      "metadata": {
        "id": "yiMykFMuBfIT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 출력은 자신만의 손실함수가 필요<br>\n",
        "=> 따라서 모델을 컴파일할 때 손실의 리스트를 전달해야함<br>\n",
        "기본적으로 케라스는 나열된 손실을 모두 더하여 최종 손실을 구해 훈련에 사용. 보조 출력보다 주 출력에 관심이 더 많다면, 주 출력의 손실에 더 많은 가중치 부여해야함"
      ],
      "metadata": {
        "id": "ZShp0-LDBmnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "metadata": {
        "id": "m3NQWhWQBm5u"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 훈련할 때 각 출력에 대한 레이블 제공해야함<br>\n",
        "여기서는 주 출력과 보조 출력이 같은 것을 예측해야하므로 동일한 레이블 사용<br>\n",
        "=> `y_train` 대신에 `(y_train, y_train)` 전달"
      ],
      "metadata": {
        "id": "kru1vuZYBnEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38nE9MuyBnVi",
        "outputId": "d51d7da2-22d4-45bf-84ce-4a2d34ae6821"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740897440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740897440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "325/363 [=========================>....] - ETA: 0s - loss: 2.3771 - main_output_loss: 2.0565 - aux_output_loss: 5.2619"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740225560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740225560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 2.2680 - main_output_loss: 1.9510 - aux_output_loss: 5.1214 - val_loss: 2.7346 - val_main_output_loss: 2.1457 - val_aux_output_loss: 8.0346\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0709 - main_output_loss: 0.8465 - aux_output_loss: 3.0910 - val_loss: 1.5914 - val_main_output_loss: 0.8960 - val_aux_output_loss: 7.8500\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8526 - main_output_loss: 0.7034 - aux_output_loss: 2.1957 - val_loss: 1.2902 - val_main_output_loss: 0.6649 - val_aux_output_loss: 6.9176\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.7558 - main_output_loss: 0.6404 - aux_output_loss: 1.7942 - val_loss: 1.1200 - val_main_output_loss: 0.6066 - val_aux_output_loss: 5.7407\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6982 - main_output_loss: 0.5992 - aux_output_loss: 1.5896 - val_loss: 0.9833 - val_main_output_loss: 0.5615 - val_aux_output_loss: 4.7794\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6574 - main_output_loss: 0.5669 - aux_output_loss: 1.4721 - val_loss: 0.8677 - val_main_output_loss: 0.5297 - val_aux_output_loss: 3.9097\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6254 - main_output_loss: 0.5402 - aux_output_loss: 1.3918 - val_loss: 0.7787 - val_main_output_loss: 0.5055 - val_aux_output_loss: 3.2383\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6002 - main_output_loss: 0.5186 - aux_output_loss: 1.3346 - val_loss: 0.7052 - val_main_output_loss: 0.4850 - val_aux_output_loss: 2.6866\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5792 - main_output_loss: 0.5004 - aux_output_loss: 1.2885 - val_loss: 0.6510 - val_main_output_loss: 0.4694 - val_aux_output_loss: 2.2860\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5624 - main_output_loss: 0.4860 - aux_output_loss: 1.2507 - val_loss: 0.6120 - val_main_output_loss: 0.4594 - val_aux_output_loss: 1.9857\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5492 - main_output_loss: 0.4748 - aux_output_loss: 1.2187 - val_loss: 0.5858 - val_main_output_loss: 0.4553 - val_aux_output_loss: 1.7601\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5385 - main_output_loss: 0.4661 - aux_output_loss: 1.1900 - val_loss: 0.5600 - val_main_output_loss: 0.4461 - val_aux_output_loss: 1.5852\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5297 - main_output_loss: 0.4593 - aux_output_loss: 1.1639 - val_loss: 0.5469 - val_main_output_loss: 0.4467 - val_aux_output_loss: 1.4489\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5224 - main_output_loss: 0.4538 - aux_output_loss: 1.1393 - val_loss: 0.5355 - val_main_output_loss: 0.4452 - val_aux_output_loss: 1.3485\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5164 - main_output_loss: 0.4496 - aux_output_loss: 1.1168 - val_loss: 0.5250 - val_main_output_loss: 0.4424 - val_aux_output_loss: 1.2683\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5112 - main_output_loss: 0.4464 - aux_output_loss: 1.0948 - val_loss: 0.5162 - val_main_output_loss: 0.4401 - val_aux_output_loss: 1.2009\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5072 - main_output_loss: 0.4442 - aux_output_loss: 1.0744 - val_loss: 0.5111 - val_main_output_loss: 0.4403 - val_aux_output_loss: 1.1488\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5030 - main_output_loss: 0.4418 - aux_output_loss: 1.0545 - val_loss: 0.5101 - val_main_output_loss: 0.4437 - val_aux_output_loss: 1.1072\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4988 - main_output_loss: 0.4392 - aux_output_loss: 1.0355 - val_loss: 0.5025 - val_main_output_loss: 0.4395 - val_aux_output_loss: 1.0689\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4961 - main_output_loss: 0.4382 - aux_output_loss: 1.0178 - val_loss: 0.5110 - val_main_output_loss: 0.4522 - val_aux_output_loss: 1.0409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIo_UfSjBn8E",
        "outputId": "a0906a2e-5763-401c-9075-7d7e538bc7dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 929us/step - loss: 0.4880 - main_output_loss: 0.4318 - aux_output_loss: 0.9943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu_WogHRCp_C",
        "outputId": "92a380b2-7c49-4426-f07f-10bcea8666c4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735bdb170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735bdb170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd735bdb170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.5 서브클래싱 API로 동적 모델 만들기"
      ],
      "metadata": {
        "id": "P4WEuMkOZILw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "시퀀셜 API와 함수형 API는 모두 선언적(declarative) (사용할 층과 연결 방식을 먼저 정의해야함, 모델에 데이터 주입하여 훈련이나 추론 시작)<br>\n",
        "-> 장점: 모델을 저장하거나 복사, 공유가 쉬움. 모델의 구조를 출력하거나 분석하기 좋음. 프레임워크가 크기를 짐작하고 타입 확인하여 에러 일찍 발견 가능. 전체 모델이 층으로 구서오딘 정적 그래프이므로 디버깅 쉬움<br>\n",
        "-> 단점: 정적<br>\n",
        "<br>\n",
        "**서브클래싱**(subclassing) API: 동적인 구조를 필요로 하는 명령형(imperative) 프로그래밍 스타일이 필요한 경우 사용"
      ],
      "metadata": {
        "id": "60fJIJDMCtNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "간단히 Model 클래스를 상속한 다음 생성자 안에서 필요하 층 만듦<br>\n",
        "그다음 `call()` 메서드 안에 수행하려는 연산 기술"
      ],
      "metadata": {
        "id": "FckyLtNJDwyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepModel(keras.models.Model):\n",
        "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "        self.main_output = keras.layers.Dense(1)\n",
        "        self.aux_output = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        input_A, input_B = inputs\n",
        "        hidden1 = self.hidden1(input_B)\n",
        "        hidden2 = self.hidden2(hidden1)\n",
        "        concat = keras.layers.concatenate([input_A, hidden2])\n",
        "        main_output = self.main_output(concat)\n",
        "        aux_output = self.aux_output(hidden2)\n",
        "        return main_output, aux_output\n",
        "\n",
        "model = WideAndDeepModel(30, activation=\"relu\")"
      ],
      "metadata": {
        "id": "mDXbXSAiZOS8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수형 API와 비슷하지만 Input 클래스의 객체 만들 필요 없음<bR>\n",
        "대신 `call()` 메서드의 input 매개변수 사용 -> `call()` 메서드 안에 원하는 어떤 계산도 사용할 수 있음"
      ],
      "metadata": {
        "id": "3PMOpoFpmcCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "유연성이 높아지면 이에 따른 비용 발생<br>\n",
        "- 모델 구조가 `call()` 메서드 안에 숨겨져있기 때문에 케라스가 쉽게 이를 분석할 수 없음<br>\n",
        "`summary()` 메서드 호출하면 층의 목록만 나열되고 층 간의 연결 정보 얻을 수 없음<br>\n",
        "- 케라스가 타입과 크기를 미리 확인할 수 없어 실수 발생하기 쉬움<br>\n",
        "\n",
        "=> 높은 유연성을 필요하지 않는다면 시퀀셜 API와 함수형 API 사용하는 것이 좋음"
      ],
      "metadata": {
        "id": "xkwLLOH8nT2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
        "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
        "\n",
        "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
        "\n",
        "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbf5oq1TZOVk",
        "outputId": "31bd9adf-6f65-4d67-9a69-60f5e2d956b0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735a0f170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735a0f170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "356/363 [============================>.] - ETA: 0s - loss: 2.1417 - output_1_loss: 2.0199 - output_2_loss: 3.2378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735bdba70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735bdba70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 3s 4ms/step - loss: 2.1210 - output_1_loss: 1.9986 - output_2_loss: 3.2225 - val_loss: 2.8539 - val_output_1_loss: 2.5208 - val_output_2_loss: 5.8515\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.9263 - output_1_loss: 0.7926 - output_2_loss: 2.1300 - val_loss: 1.5743 - val_output_1_loss: 1.2249 - val_output_2_loss: 4.7190\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.7806 - output_1_loss: 0.6730 - output_2_loss: 1.7492 - val_loss: 1.1348 - val_output_1_loss: 0.8106 - val_output_2_loss: 4.0528\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7027 - output_1_loss: 0.6126 - output_2_loss: 1.5139 - val_loss: 0.9375 - val_output_1_loss: 0.6529 - val_output_2_loss: 3.4992\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6474 - output_1_loss: 0.5703 - output_2_loss: 1.3416 - val_loss: 0.7974 - val_output_1_loss: 0.5528 - val_output_2_loss: 2.9988\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6064 - output_1_loss: 0.5384 - output_2_loss: 1.2180 - val_loss: 0.7264 - val_output_1_loss: 0.5128 - val_output_2_loss: 2.6496\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5766 - output_1_loss: 0.5151 - output_2_loss: 1.1304 - val_loss: 0.6632 - val_output_1_loss: 0.4782 - val_output_2_loss: 2.3281\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5544 - output_1_loss: 0.4977 - output_2_loss: 1.0644 - val_loss: 0.6274 - val_output_1_loss: 0.4627 - val_output_2_loss: 2.1100\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5371 - output_1_loss: 0.4840 - output_2_loss: 1.0154 - val_loss: 0.6025 - val_output_1_loss: 0.4536 - val_output_2_loss: 1.9429\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5239 - output_1_loss: 0.4735 - output_2_loss: 0.9772 - val_loss: 0.5817 - val_output_1_loss: 0.4456 - val_output_2_loss: 1.8068\n",
            "162/162 [==============================] - 0s 988us/step - loss: 0.5130 - output_1_loss: 0.4627 - output_2_loss: 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735c2bc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd735c2bc20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd735c2bc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zruJdw5YmzxZ",
        "outputId": "ee888788-0aa2-4e9c-9e1f-9555f9486e01"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"wide_and_deep_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            multiple                  210       \n",
            "                                                                 \n",
            " dense_16 (Dense)            multiple                  930       \n",
            "                                                                 \n",
            " dense_17 (Dense)            multiple                  36        \n",
            "                                                                 \n",
            " dense_18 (Dense)            multiple                  31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,207\n",
            "Trainable params: 1,207\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.6 모델 저장과 복원"
      ],
      "metadata": {
        "id": "UFPZYmXIZIRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "시퀀셜 API와 함수형 API를 사용하면 훈련된 케라스 모델 저장하는 것은 쉬움"
      ],
      "metadata": {
        "id": "MVSxb2LjoN8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    "
      ],
      "metadata": {
        "id": "_En8rMB2ZSe5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g-e3n2WZShP",
        "outputId": "cff21df8-c340-49ab-fe05-f7d4e1209df7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd741618830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd741618830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "336/363 [==========================>...] - ETA: 0s - loss: 1.8466"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e687a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e687a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 1.7708 - val_loss: 0.7858\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.7263 - val_loss: 0.6888\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6499 - val_loss: 0.6225\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.5610\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5240\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5404 - val_loss: 0.4974\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5160 - val_loss: 0.4785\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.4574\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.4423\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4640 - val_loss: 0.4303\n",
            "162/162 [==============================] - 0s 801us/step - loss: 0.4448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_keras_model.h5\")"
      ],
      "metadata": {
        "id": "W5xpaAYHoYaH"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스는 HDF5 포맷을 사용하여 (모든 층의 하이퍼파라미터 포함하여) 모델 구조와 층의 모든 모델 파라미터(즉 연결 가중치와 편향)를 저장. 또한 (하이퍼파라미터와 현재 상태를 포함하여) 옵티마이저도 저장."
      ],
      "metadata": {
        "id": "LXQTEwRpok4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 하나의 파이썬 스크립트에서 모델을 훈련하고 저장한 다음 하나 이상의 스크립트에서 모델을 로드하고 예측을 만드는데 활용. 모델 로드는 다음과 같음."
      ],
      "metadata": {
        "id": "NYsV9Cs8o8t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ],
      "metadata": {
        "id": "fOl2ucH7ogu_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWrhkyv1ogyA",
        "outputId": "e6a055ad-ed8a-4d70-84a0-06c63c7f474a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd741f14710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd741f14710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7777177],\n",
              "       [1.5822684],\n",
              "       [3.3043728]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.7 콜백 사용하기"
      ],
      "metadata": {
        "id": "NDiajVZkZIZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fit()` 메서드의 `callbacks` 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체 리스트 저장. 또는 에포크의 시작이나 끝, 각 배치 처리 전후에 호출할 수도 있음."
      ],
      "metadata": {
        "id": "pbAnkTaYpdji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    "
      ],
      "metadata": {
        "id": "tQNd9DY2Pjkr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련하는 동안 검증 세트를 사용하면 `ModelCheckpoint`를 만들 때 `save_best_only=True`로 지정할 수 있음<br>\n",
        "=> 이렇게 하면 최상의 검증 세트 점수에서만 모델 저장. 과대적합 걱정 x."
      ],
      "metadata": {
        "id": "9ifEEus_qYuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb])\n",
        "model = keras.models.load_model(\"my_keras_model.h5\") # 최상의 모델로 롤백\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnlYeya0ptJZ",
        "outputId": "4d1f1bfd-72de-40b1-bf3c-406826c71894"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740b6c950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740b6c950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "334/363 [==========================>...] - ETA: 0s - loss: 2.2851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b74830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b74830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 2.1781 - val_loss: 1.7808\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.8040 - val_loss: 0.8024\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.7037 - val_loss: 0.8151\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6577 - val_loss: 0.6666\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6218 - val_loss: 0.6082\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5898 - val_loss: 0.5610\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5632 - val_loss: 0.5389\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.5031\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.4796\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5020 - val_loss: 0.4629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b1a7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b1a7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "162/162 [==============================] - 0s 851us/step - loss: 0.4806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "조기 종료를 구현하는 또 다른 방법은 `EarlyStopping` 콜백 사용<br>\n",
        "-> 일정 에포크(`patience` 매개변수로 지정) 동안 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤"
      ],
      "metadata": {
        "id": "1Av_fGVEZVuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZAIUytVptHJ",
        "outputId": "bfe5c74b-7967-4e84-9668-9b8060aa1e9e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7407e3290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7407e3290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "325/363 [=========================>....] - ETA: 0s - loss: 0.4870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b1a170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b1a170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4873 - val_loss: 0.4494\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4417\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.4321\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4526 - val_loss: 0.4403\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4299\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4346\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4304 - val_loss: 0.4245\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4247 - val_loss: 0.4177\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4254\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.4273\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4139\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4298\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4309\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4100\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4108\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3959 - val_loss: 0.4028\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4101\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.4071\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4044\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4376\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4313\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4353\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3837\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3905\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.4226\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3760 - val_loss: 0.4138\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.3831\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 0.4016\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3835\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3951\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3853\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4027\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.3764\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3652 - val_loss: 0.3716\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3885\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3565\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3720\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3634\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3549\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3652\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3578 - val_loss: 0.3763\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3701\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3717\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3799\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3521\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3507\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3522 - val_loss: 0.3503\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3613\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3550\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3341\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3539\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.3344\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3572\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3477\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3409\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3425\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3337\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.3402\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3454\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3468\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3497\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3426 - val_loss: 0.3418\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3377\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3416 - val_loss: 0.3289\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3340\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3306\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3420\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3376\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3348\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.3334\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.3433\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3294\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3213\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3369 - val_loss: 0.3412\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3337\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3265\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3427\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3352 - val_loss: 0.3406\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3348 - val_loss: 0.3294\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.3257\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3276\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.3158\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3334 - val_loss: 0.3176\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3330 - val_loss: 0.3299\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3240\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3141\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3217\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3253\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3312 - val_loss: 0.3343\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3359\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3307 - val_loss: 0.3161\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3270\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3301 - val_loss: 0.3203\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3209\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3302\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3257\n",
            "162/162 [==============================] - 0s 800us/step - loss: 0.3335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 향상되지 않으면 훈련이 자동으로 중지되기 때문에 에포크의 숫자를 크게 지정해도 괜찮음. 이 경우 EarlyStopping 콜백이 훈련이 끝난 후 최상의 가중치를 복원하기 때문에 저장된 모델을 따로 복원할 필요 없음"
      ],
      "metadata": {
        "id": "DuFCIPIOrbAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 더 많은 제어를 원한다면 사용자 정의 콜백을 만들 수 있음"
      ],
      "metadata": {
        "id": "N0onIPUUrr7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
      ],
      "metadata": {
        "id": "xajxqJLsrwbM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
        "history = model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[val_train_ratio_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhPBpQwQr06M",
        "outputId": "f10294d0-17d9-4427-934b-c5fb838622b7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "316/363 [=========================>....] - ETA: 0s - loss: 0.3319\n",
            "val/train: 0.97\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2.8 텐서보드를 사용해 시각화하기"
      ],
      "metadata": {
        "id": "WVedpJsCZV3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서보드(TensorBoard)는 매우 좋은 인터렉티브 시각화 도구<br>\n",
        "- 훈련하는 동안 학습 곡선을 그리거나 여러 실행 간의 학습 곡선을 비교하고 계산 그래프 시각화와 훈련 통계 분석을 수행할 수 있음\n",
        "- 모델이 생성한 이미지를 확인하거나 3D에 투영된 복잡한 다차원 데이터를 시각화하고 자동으로 클러스터링을 해주는 등의 기능 제공"
      ],
      "metadata": {
        "id": "M67jwPhXZV6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "run_logdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hFbwjveHZbmg",
        "outputId": "d84f83dc-fb35-453f-93d9-3d4297e22a06"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_logs/run_2022_11_15-07_01_07'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08JqamSsZbo7",
        "outputId": "3e6090f0-bc09-4b32-fe68-45bc7f9b5e87"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740fc84d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740fc84d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "324/363 [=========================>....] - ETA: 0s - loss: 1.7370"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd74089d560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd74089d560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.6411 - val_loss: 0.8058\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7431 - val_loss: 0.7239\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6647 - val_loss: 0.6913\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6170 - val_loss: 0.6103\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5800 - val_loss: 0.5594\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.5367\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.5170\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5023 - val_loss: 0.4777\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.4602\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4460\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.4418\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4227\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4187\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4177\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4260\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4215\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4169 - val_loss: 0.4322\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4377\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4221\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4545\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.4407\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4461\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4056\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4198\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4400\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4419\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4004\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4229\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3875 - val_loss: 0.4114\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3858 - val_loss: 0.4313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.3 신경망 하리퍼파라미터 튜닝하기"
      ],
      "metadata": {
        "id": "0kMHl2bjZV_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망의 유연성은 단점이기도 함<br>\n",
        "=> 조정할 하이퍼파라미터가 많기 때문"
      ],
      "metadata": {
        "id": "o6kiUt8lZg1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "방법1: 많은 하이퍼파라미터 조합을 시도해보고 어떤 것이 검증 세트에서 가장 좋은 점수를 내는지 확인<br>\n",
        "=> `GridSearchCV`나 `RandomizedSearchCV`를 사용하여 하이퍼파라미터 공간 탐색"
      ],
      "metadata": {
        "id": "lzNQJHvTtKRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OLucHj2BZf7k"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 주어진 입력 크기와 은닉층 개수, 뉴런 개수로 (한 개의 출력 뉴런만 있는) 단변량(univariate) 회귀를 위한 간단한 Sequential 모델 만듦\n",
        "- 지정된 학습률을 사용하는 SGD optimizer로 모델을 컴파일"
      ],
      "metadata": {
        "id": "du5i4HqUZhkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`build_model()` 함수를 이용해 KerasRegressor 클래스의 객체 만듦"
      ],
      "metadata": {
        "id": "9aygKfhNuG2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "metadata": {
        "id": "2xbALvHEZhs3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KerasRegressor 객체는 `build_model()` 함수로 만들어진 케라스 모델을 감싸는 간단한 래퍼(wrapper)<br>\n",
        "해당 객체를 만들 때 어떤 하이퍼파라미터도 지정하지 않았으므로 `build_model()`에 정의된 기본 하이퍼파라미터 사용"
      ],
      "metadata": {
        "id": "fOqZNh7cuP-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOuEdyjuZiKC",
        "outputId": "37b9e204-9c1b-4954-9e7e-59bfa13376ee"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7358c83b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7358c83b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "337/363 [==========================>...] - ETA: 0s - loss: 1.2322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd74089db00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd74089db00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.1949 - val_loss: 1.0089\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6160 - val_loss: 0.6810\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5266 - val_loss: 0.4744\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.5233\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4518\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.5494\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4027\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.3924\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4657\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4108 - val_loss: 0.5034\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4085 - val_loss: 0.4882\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4059 - val_loss: 1.1912\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4711\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4980\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3718\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4188\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4429\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.4068\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3647\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.7396\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3893 - val_loss: 0.3614\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.8090\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.9630\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 1.2536\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3972\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3799 - val_loss: 0.9234\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.9778\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 1.7420\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.8715\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 2.1665\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3898 - val_loss: 0.9365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7358deed0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = keras_reg.score(X_test, y_test)\n",
        "y_pred = keras_reg.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNfnywq9ZiRS",
        "outputId": "25fc80ff-9dd2-45e0-e060-9c44455aae98"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 934us/step - loss: 0.3740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd7410e8050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fd7410e8050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fit()` 메서드에 지정한 모든 매개변수는 케라스 모델로 전달<br>\n",
        "sklearn은 손실이 아닌 점수를 계산하기 때문에 출력 점수는 음수의 MSE"
      ],
      "metadata": {
        "id": "dJgyImjHZjBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 하나를 훈련하고 평가하려는 것이 아니라 수백 개의 모델을 훈련하고 검증 세트에서 최상의 모델을 선택해야함. 하이퍼파라미터가 많으므로 그리드 탐색보다 랜덤 탐색을 사용하는 것이 좋음<br>\n",
        "은닉층 개수, 뉴런 개수, 학습률 사용해 하이퍼파라미터 탐색 수행"
      ],
      "metadata": {
        "id": "o5l6-F3iZjGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3r38fYrZjQV",
        "outputId": "278d0c62-6b07-4e00-9bca-d2306874bd85"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f49320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f49320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "219/242 [==========================>...] - ETA: 0s - loss: 0.7967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740d7db90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740d7db90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7697 - val_loss: 0.4348\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.4076\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.3959\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.3897\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.3938\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.3899\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.3911\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4168 - val_loss: 0.3813\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.3882\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4204\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.3853\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.3885\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.3749\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 0.3724\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 0.3674\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.3683\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3981 - val_loss: 0.3629\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.3673\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3666\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.3601\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.3677\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3656\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4041\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.3633\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3718\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3635\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.3628\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.3660\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3599\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3625\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.3561\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.3543\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3578\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3561\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.3564\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3535\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3521\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3802 - val_loss: 0.3591\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.3562\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3516\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.3574\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3499\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3493\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3519\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3490\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.3505\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3460\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3488\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3458\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3470\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3898\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.3500\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3443\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.3503\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3470\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3446\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3434\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.3455\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.3457\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3649 - val_loss: 0.3518\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3498\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3663 - val_loss: 0.4081\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3450\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3526\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.3450\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3438\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3513\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3842\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  41.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740dc8440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740dc8440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "232/242 [===========================>..] - ETA: 0s - loss: 1.1507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740d9c3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740d9c3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1327 - val_loss: 1.0406\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5712 - val_loss: 0.4929\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.5390\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4668\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.4563\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4263\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4333\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.4069\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4170\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.3999\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4350\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4128\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4271\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4254 - val_loss: 0.4092\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.3971\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4136\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4107\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4253 - val_loss: 0.4040\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4085\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.4237\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4178\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4176 - val_loss: 0.4117\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4126\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4195\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.4264\n",
            "121/121 [==============================] - 0s 918us/step - loss: 0.4382\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   9.6s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7410b2dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7410b2dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "205/242 [========================>.....] - ETA: 0s - loss: 1.1879"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd74089dcb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd74089dcb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.2596 - val_loss: 163.0837\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6282 - val_loss: 1.5479\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 7.8149\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8443 - val_loss: 14.8219\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7293 - val_loss: 83.3037\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5108 - val_loss: 0.4611\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.4332\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.4337\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4504 - val_loss: 0.4494\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4329\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4541\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.4464\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4242\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.4898\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4419 - val_loss: 0.4280\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4800\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4310\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4341\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4878\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.4559\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.4638\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4209\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4178\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 0.4631\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4112\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4191\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.5077\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4074\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.4742\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4628\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.4504\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.5128\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4987\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 0.5125\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4866\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 0.4516\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.4170\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4960\n",
            "121/121 [==============================] - 0s 808us/step - loss: 0.4158\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  14.6s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd741020d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd741020d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "198/242 [=======================>......] - ETA: 0s - loss: 1.1283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7358c8710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7358c8710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0483 - val_loss: 18.9225\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8777 - val_loss: 29.1266\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7115 - val_loss: 9.3468\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 8.4873\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5514\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.3982\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3590\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3606\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3645\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3628\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3618\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.3708\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3585\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3459 - val_loss: 0.3625\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.3562\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.3566\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.3559\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.3541\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3554\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.3519\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3515\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.3535\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3511\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3229 - val_loss: 0.3302\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.3450\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3184 - val_loss: 0.3246\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3181 - val_loss: 0.3295\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3176 - val_loss: 0.3403\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.3339\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3135\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3149\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3064\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3094 - val_loss: 0.3207\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3336\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3024\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3259\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3050 - val_loss: 0.2989\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3328\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3031 - val_loss: 0.3057\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3214\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3020\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3005\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2998 - val_loss: 0.2993\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3311\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.2917\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.3059\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.3163\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3066\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.2884\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.3099\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3258\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2914 - val_loss: 0.3118\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.3139\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.2947\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2888 - val_loss: 0.3066\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3001\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2873 - val_loss: 0.3128\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2871 - val_loss: 0.3285\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2864 - val_loss: 0.2858\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2852 - val_loss: 0.2989\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2855 - val_loss: 0.3134\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2840 - val_loss: 0.3293\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2843 - val_loss: 0.2998\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 0.3313\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2815 - val_loss: 0.2984\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2820 - val_loss: 0.2873\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2813 - val_loss: 0.3113\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2801 - val_loss: 0.3145\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2796 - val_loss: 0.3133\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3163\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  28.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7407e3440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7407e3440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "204/242 [========================>.....] - ETA: 0s - loss: 1.0083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7359a8cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7359a8cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9428 - val_loss: 0.9983\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.6773\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.6964\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.4890\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.3759\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.3910\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.5170\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.6271\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.7534\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.6301\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.6846\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.7069\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.8121\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.7847\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.7734\n",
            "121/121 [==============================] - 0s 836us/step - loss: 0.3569\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   6.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735911830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735911830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "192/242 [======================>.......] - ETA: 0s - loss: 1.0339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735c1a200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735c1a200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9474 - val_loss: 1.4012\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5426 - val_loss: 6.9119\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5024 - val_loss: 9.1706\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - val_loss: 2.3111\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4079\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4086\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.4045\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3928\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3985\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3649\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.3930\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.3731\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.3599\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.4121\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3351\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3601\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3402\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.3499\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3702\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3376\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 0.3621\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3201\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3580\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.3710\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3147\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3427\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.3567\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3151\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3558\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3262 - val_loss: 0.3589\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.3241\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.3580\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3216 - val_loss: 0.3357\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.3497\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3181 - val_loss: 0.3078\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3171 - val_loss: 0.3700\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3150 - val_loss: 0.3125\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3146 - val_loss: 0.3673\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 0.3054\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3439\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.3133\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3551\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.3123\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3064 - val_loss: 0.3770\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.3038\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.4024\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3023 - val_loss: 0.3151\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3035 - val_loss: 0.3740\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.2995\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.4044\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2993 - val_loss: 0.2909\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2976 - val_loss: 0.4761\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 0.4461\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.4232\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2976 - val_loss: 0.2892\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2933 - val_loss: 0.3330\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3104\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2932 - val_loss: 0.2960\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2910 - val_loss: 0.3202\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3075\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2902 - val_loss: 0.3925\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2889 - val_loss: 0.2860\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2887 - val_loss: 0.3230\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2884 - val_loss: 0.2886\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.3516\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.2841\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.2901\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.3748\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.3741\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.6862\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.4632\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2860 - val_loss: 0.5269\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.4905\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 1.1274\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2855 - val_loss: 0.4452\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2804 - val_loss: 2.1910\n",
            "121/121 [==============================] - 0s 926us/step - loss: 0.3013\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  41.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7b24d0dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7b24d0dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "213/242 [=========================>....] - ETA: 0s - loss: 4.1424"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7375b2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7375b2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.9960 - val_loss: 5.0752\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 2.1502 - val_loss: 3.9713\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.4275 - val_loss: 2.6721\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0874 - val_loss: 1.7129\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.9120 - val_loss: 1.1519\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.8167 - val_loss: 0.8727\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7629 - val_loss: 0.7461\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7308 - val_loss: 0.6983\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7098 - val_loss: 0.6763\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.6644\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6813 - val_loss: 0.6565\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6703 - val_loss: 0.6460\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6600 - val_loss: 0.6409\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6506 - val_loss: 0.6321\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.6211\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6330 - val_loss: 0.6136\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 0.6039\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6167 - val_loss: 0.5980\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 0.5909\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6017 - val_loss: 0.5840\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5947 - val_loss: 0.5723\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5876 - val_loss: 0.5661\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5810 - val_loss: 0.5588\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5744 - val_loss: 0.5533\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 0.5448\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5622 - val_loss: 0.5372\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5563 - val_loss: 0.5329\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.5252\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5452 - val_loss: 0.5200\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.5149\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5105\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 0.5046\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.5004\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.4954\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5169 - val_loss: 0.4904\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.4871\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 0.4812\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.4785\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.4744\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.4706\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4945 - val_loss: 0.4675\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.4641\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.4609\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4581\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.4555\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4797 - val_loss: 0.4527\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.4501\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.4474\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.4452\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4431\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.4407\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4655 - val_loss: 0.4384\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.4364\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.4344\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.4326\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 0.4308\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4290\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4275\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4259\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4244\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.4231\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4219\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4204\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4446 - val_loss: 0.4193\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4185\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.4171\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4406 - val_loss: 0.4161\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.4159\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4147\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4135\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4129\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4122\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.4110\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4111\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4111\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.4101\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4097\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4098\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 0.4089\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4080\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.4086\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.4101\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.4093\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.4091\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4079\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.4094\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.4082\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4075\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4055\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.4069\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.4055\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.4053\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4053\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4042\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4054\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.4058\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.4048\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4037\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4071\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.4056\n",
            "121/121 [==============================] - 0s 938us/step - loss: 0.4189\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  41.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7410de950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7410de950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "198/242 [=======================>......] - ETA: 0s - loss: 2.9978"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740fff950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740fff950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.7682 - val_loss: 5.3927\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.2850 - val_loss: 6.3156\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9007 - val_loss: 6.3543\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7922 - val_loss: 5.8888\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.7496 - val_loss: 5.2649\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7248 - val_loss: 4.7014\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.7060 - val_loss: 4.1820\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6898 - val_loss: 3.7118\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 3.3065\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6618 - val_loss: 2.9450\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6492 - val_loss: 2.6389\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6375 - val_loss: 2.3485\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6265 - val_loss: 2.1040\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 1.8975\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6065 - val_loss: 1.7098\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 1.5514\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5887 - val_loss: 1.4090\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5806 - val_loss: 1.2830\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5728 - val_loss: 1.1744\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5655 - val_loss: 1.0793\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5585 - val_loss: 0.9928\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.9253\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.8626\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.8102\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5341 - val_loss: 0.7619\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 0.7207\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.6840\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.6522\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.6316\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 0.6058\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.5817\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 0.5647\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.5485\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4945 - val_loss: 0.5374\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.5281\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5157\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.5077\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.4994\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.4929\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.4878\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.4844\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.4795\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.4741\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4708\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.4680\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.4644\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4629\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4619\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4617\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.4599\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4575\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4578\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4496 - val_loss: 0.4587\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4589\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4604\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4620\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.4614\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4649\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4672\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.4680\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4719\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4521\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  41.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740b6c200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740b6c200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "208/242 [========================>.....] - ETA: 0s - loss: 3.8841"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740fffd40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740fffd40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.7018 - val_loss: 2.3597\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.7387 - val_loss: 1.3313\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0890 - val_loss: 0.9862\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.8548 - val_loss: 0.8002\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7643 - val_loss: 0.7236\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7242 - val_loss: 0.6944\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 0.6821\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6866 - val_loss: 0.6869\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 0.6682\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6637 - val_loss: 0.6466\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6534 - val_loss: 0.6496\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6443 - val_loss: 0.6342\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6354 - val_loss: 0.6181\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6269 - val_loss: 0.6117\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6187 - val_loss: 0.6006\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.6040\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6035 - val_loss: 0.5911\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.5821\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5891 - val_loss: 0.5900\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5828 - val_loss: 0.5773\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5763 - val_loss: 0.5691\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - val_loss: 0.5646\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5643 - val_loss: 0.5493\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.5417\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5530 - val_loss: 0.5361\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5478 - val_loss: 0.5266\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 0.5304\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5379 - val_loss: 0.5208\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5331 - val_loss: 0.5171\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5087\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5053\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.5006\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5162 - val_loss: 0.4964\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.4903\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.4856\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 0.4785\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5010 - val_loss: 0.4736\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.4709\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4942 - val_loss: 0.4670\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.4638\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.4607\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4574\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.4544\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.4516\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4771 - val_loss: 0.4491\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4746 - val_loss: 0.4465\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4723 - val_loss: 0.4442\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.4418\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.4396\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.4374\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.4354\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4334\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4596 - val_loss: 0.4321\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4311\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4559 - val_loss: 0.4303\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4306\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.4287\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4509 - val_loss: 0.4262\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.4257\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4237\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4257\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 0.4244\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4247\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.4237\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4231\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4248\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.4204\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4218\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4215\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4190\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4166\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4168\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4172\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.4192\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4204\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.4240\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4212\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.4217\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.4212\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.4225\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.4196\n",
            "121/121 [==============================] - 0s 976us/step - loss: 0.4296\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  41.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735ccb680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735ccb680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "240/242 [============================>.] - ETA: 0s - loss: 1.7165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740825f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740825f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7092 - val_loss: 10.8368\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8158 - val_loss: 2.0993\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 0.5579\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5697 - val_loss: 0.5178\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.4826\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4958 - val_loss: 0.4619\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.4312\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.4376\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.4292\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.4142\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.3904\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.3876\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4027\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4261\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4029\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3965\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4207\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.3996\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4085\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.3982\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4028\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3899\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3846\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   9.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd741618710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd741618710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "200/242 [=======================>......] - ETA: 0s - loss: 1.6674"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e0c290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e0c290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5204 - val_loss: 3.7378\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7402 - val_loss: 0.7359\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6404 - val_loss: 0.9528\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5761 - val_loss: 1.8878\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 2.6650\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 2.7808\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 2.7880\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 2.6149\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 2.1473\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 1.6998\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 1.4139\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 1.1899\n",
            "121/121 [==============================] - 0s 942us/step - loss: 0.4560\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   5.2s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd74084e830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd74084e830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "236/242 [============================>.] - ETA: 0s - loss: 1.8660"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b744d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740b744d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.8406 - val_loss: 2.5481\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6861 - val_loss: 0.6509\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5843 - val_loss: 0.5352\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5403 - val_loss: 0.4959\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.4980\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.4503\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4572 - val_loss: 0.4297\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4089\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.4645\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4196 - val_loss: 0.3911\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4547\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 0.4016\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.3803\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4658\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.3713\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.4339\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3651\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3943\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4248\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3889\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.3881\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.3671\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3712\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.4223\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3503\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3615\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3657 - val_loss: 0.4530\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3632\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4990\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3597\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3607 - val_loss: 0.3883\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3595 - val_loss: 0.4056\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.4084\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.4483\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3521\n",
            "121/121 [==============================] - 0s 937us/step - loss: 0.3549\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  14.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd738dfe9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd738dfe9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "221/242 [==========================>...] - ETA: 0s - loss: 1.3959"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735dcf7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735dcf7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4008 - val_loss: 540.8848\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.6527 - val_loss: 1322.1606\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 12.1240 - val_loss: 7835.6958\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 27.1682 - val_loss: 28336.4707\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 120.2205 - val_loss: 136078.7344\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 5072.7617 - val_loss: 593800.0625\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 6073.9297 - val_loss: 2671194.0000\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 89198.0078 - val_loss: 11948000.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 184464.0625 - val_loss: 54024852.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2327751.2500 - val_loss: 264147408.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4100927.2500 - val_loss: 1167836288.0000\n",
            "121/121 [==============================] - 0s 924us/step - loss: 3091406.5000\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   4.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735bf5cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735bf5cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "207/242 [========================>.....] - ETA: 0s - loss: 0.9677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735dcf950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735dcf950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9009 - val_loss: 17.9977\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 23.6686\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 25.6516\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 22.9288\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 22.1705\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 21.4778\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 20.0228\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5100 - val_loss: 22.5841\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5068 - val_loss: 20.1429\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 10.7269\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 19.7513\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 24.3393\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 25.9596\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 10.5308\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 17.1948\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 21.8377\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 11.7753\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 14.1563\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 20.9823\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 12.3625\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 25.9151\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5132 - val_loss: 16.0463\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 19.4878\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 12.1055\n",
            "121/121 [==============================] - 0s 919us/step - loss: 0.7813\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   9.3s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735b5ad40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735b5ad40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "235/242 [============================>.] - ETA: 0s - loss: 1.1095"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735ad9c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735ad9c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1068 - val_loss: 159.5891\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.6824 - val_loss: 22.7768\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.1405 - val_loss: 561.6631\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 24.4221 - val_loss: 506.3159\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1258 - val_loss: 2266.0061\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 7.7290 - val_loss: 1196.1788\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.1699 - val_loss: 1305.3683\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 35.4105 - val_loss: 1196.8810\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 9.6389 - val_loss: 1159.5369\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.3576 - val_loss: 157.6044\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 10.4146 - val_loss: 85.8061\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6327 - val_loss: 0.6838\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.7252 - val_loss: 706.1638\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 8.1188 - val_loss: 411.5789\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.0950 - val_loss: 993.7607\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 34.4451 - val_loss: 803.7979\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 8.4994 - val_loss: 1063.4398\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 3.5815 - val_loss: 461.9431\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 23.0873 - val_loss: 283.1018\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 3.2819 - val_loss: 317.1609\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.0157 - val_loss: 516.7094\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.1766 - val_loss: 361.4213\n",
            "121/121 [==============================] - 0s 886us/step - loss: 0.6023\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  10.6s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73593eb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73593eb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "198/242 [=======================>......] - ETA: 0s - loss: 1.0854"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd767d2ea70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd767d2ea70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0199 - val_loss: 11.5704\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7079 - val_loss: 2.7042\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.6647\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4654 - val_loss: 0.5138\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4566\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4749\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4499\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.4614\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.4468\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.4469\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.4266\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.4315\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.4079\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.4922\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3483 - val_loss: 0.3986\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3458 - val_loss: 0.4282\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3429 - val_loss: 0.5112\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.4179\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.5395\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3796\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.4517\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.4676\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.4374\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3452\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3795\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3257 - val_loss: 0.3662\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3251 - val_loss: 0.3916\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.4359\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.4326\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3201 - val_loss: 0.3351\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3555\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3672\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3154 - val_loss: 0.4227\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.4369\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3092\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.4109\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3341\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3098 - val_loss: 0.4074\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3094 - val_loss: 0.3189\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3086 - val_loss: 0.3879\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3725\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3061 - val_loss: 0.3096\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.3482\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.4193\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3049 - val_loss: 0.3031\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.3742\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.3611\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3027 - val_loss: 0.3505\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3177\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 0.3781\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3897\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3378\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.3665\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2979 - val_loss: 0.3061\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2959 - val_loss: 0.3905\n",
            "121/121 [==============================] - 0s 972us/step - loss: 0.3337\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  22.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73a749f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73a749f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "212/242 [=========================>....] - ETA: 0s - loss: 1.2349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7410e8cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7410e8cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1567 - val_loss: 1.0816\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5566 - val_loss: 1.8573\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 1.5882\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 1.1602\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.7343\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4119\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3779\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3775 - val_loss: 0.4159\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.5404\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4683\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3590 - val_loss: 0.4588\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.5624\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.6519\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.5388\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.6625\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.5024\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3408 - val_loss: 0.4395\n",
            "121/121 [==============================] - 0s 912us/step - loss: 0.3537\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   7.2s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7410b2290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7410b2290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "209/242 [========================>.....] - ETA: 0s - loss: 1.0375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740980c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd740980c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9880 - val_loss: 3.9832\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 5.6363\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 2.2048\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4886\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.3873\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3902 - val_loss: 0.4151\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.3880\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.3891\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.4463\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.3505\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3668 - val_loss: 0.4760\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3870\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3608 - val_loss: 0.3532\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.4419\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.3387\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 0.4166\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3342\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.3860\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.3951\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3734\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3514\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.3227\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.3663\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3845\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3179\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.3443\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.4345\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.3277\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.3277\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 0.3537\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3406\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.3759\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.3638\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3859\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3269\n",
            "121/121 [==============================] - 0s 967us/step - loss: 0.3263\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  20.9s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7379cbb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7379cbb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - ETA: 0s - loss: 1.7465"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737bf6a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737bf6a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7465 - val_loss: 4.3471\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7580 - val_loss: 0.7274\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6186 - val_loss: 0.5620\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5718 - val_loss: 0.5239\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5385 - val_loss: 0.4986\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 0.4726\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4898 - val_loss: 0.4513\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.4529\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.4524\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4301\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4213\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4130\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4120\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4270 - val_loss: 0.4292\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 0.4186\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.4071\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.4257\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4009\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4073\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.4043\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.4044\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4001\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4088\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.3810\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4057\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.3787\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3989\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.3855\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.4040\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3754\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.3714\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3670\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3947\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3965\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3621\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3835 - val_loss: 0.4114\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3593\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.4227\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3594\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4010\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.3728\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.3603\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.3616\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4170\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.3597\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3769\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3998\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3845\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  20.9s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7378faa70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7378faa70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "213/242 [=========================>....] - ETA: 0s - loss: 2.0901"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd741ee2050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd741ee2050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.9233 - val_loss: 4.4641\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6537 - val_loss: 0.9036\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5890 - val_loss: 0.6580\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 1.4358\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 2.2975\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4996 - val_loss: 2.8953\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4822 - val_loss: 3.1192\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 3.2946\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4571 - val_loss: 2.9548\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 2.5823\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 2.3305\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 2.1236\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 1.7990\n",
            "121/121 [==============================] - 0s 858us/step - loss: 0.4689\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   5.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7377e5dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7377e5dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "205/242 [========================>.....] - ETA: 0s - loss: 1.8062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737715b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737715b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.6794 - val_loss: 5.2522\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 4.6583\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6387 - val_loss: 1.7668\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6013 - val_loss: 1.2836\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5061\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5153 - val_loss: 0.6277\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.4761\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4791 - val_loss: 0.4367\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4654 - val_loss: 0.5871\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4167\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.5009\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4195\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.4005\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.5447\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.3922\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.5845\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4274\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4276\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.4263\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4040\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4351\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3745\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.3909\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4480\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.3857\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3993 - val_loss: 0.3883\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.5116\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3801\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3949 - val_loss: 0.7662\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.3831\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4530\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.4156\n",
            "121/121 [==============================] - 0s 954us/step - loss: 0.3893\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  12.5s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73764c3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd73764c3b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "241/242 [============================>.] - ETA: 0s - loss: 1.0838"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd73767d200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd73767d200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0819 - val_loss: 0.6179\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5500 - val_loss: 3.3922\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 2.4191\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.4920\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.3734\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3811 - val_loss: 0.4213\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3665\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3598 - val_loss: 0.4383\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3782\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.4116\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3300\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3624\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.4419\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.3179\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.5404\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3169\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3245 - val_loss: 0.4133\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3225 - val_loss: 0.3470\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3182 - val_loss: 0.4469\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3046\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3151 - val_loss: 0.4535\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3209\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.4036\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3123 - val_loss: 0.3462\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3085 - val_loss: 0.4266\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3059 - val_loss: 0.3237\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3052 - val_loss: 0.3905\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3337\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3956\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 0.3192\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3304\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  13.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7401d04d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7401d04d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.9487"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e68320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e68320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9372 - val_loss: 0.6602\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.8619\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.7788\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.5587\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3850\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3578\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.5307\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.6256\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.8663\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.5734\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.7210\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.7823\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.9658\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3264 - val_loss: 0.7248\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.8045\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.8197\n",
            "121/121 [==============================] - 0s 976us/step - loss: 0.3460\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   7.3s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7377a23b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7377a23b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "227/242 [===========================>..] - ETA: 0s - loss: 1.0356"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737709830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737709830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0059 - val_loss: 1.8172\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 2.3028\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 1.0580\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.7162\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.3621\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3924\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.3753\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3497\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3568 - val_loss: 0.4140\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.3346\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.4863\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.3290\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3296\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.4439\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3301\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.4140\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3175\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 0.3199\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3256 - val_loss: 0.3794\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3197\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3214 - val_loss: 0.3674\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3256 - val_loss: 0.3605\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.3283\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3172 - val_loss: 0.3366\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3143 - val_loss: 0.3072\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3111 - val_loss: 0.3065\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3096 - val_loss: 0.3545\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3035\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3903\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3157\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.3074\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.4420\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.2956\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2974 - val_loss: 0.3953\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3091\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2961 - val_loss: 0.3461\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2944 - val_loss: 0.2925\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2935 - val_loss: 0.3522\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2916 - val_loss: 0.2912\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2900 - val_loss: 0.3154\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2877 - val_loss: 0.2978\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.3252\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2869 - val_loss: 0.3069\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.3326\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 0.3040\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 0.3154\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2801 - val_loss: 0.2854\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2802 - val_loss: 0.2902\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2778 - val_loss: 0.3308\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2779 - val_loss: 0.2997\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2763 - val_loss: 0.3814\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.2903\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2748 - val_loss: 0.2995\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 0.2843\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2722 - val_loss: 0.2918\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2721 - val_loss: 0.2848\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2706 - val_loss: 0.2969\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2715 - val_loss: 0.2921\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2688 - val_loss: 0.2983\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2684 - val_loss: 0.3009\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2670 - val_loss: 0.2847\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2668 - val_loss: 0.3263\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2667 - val_loss: 0.3011\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2658 - val_loss: 0.3743\n",
            "121/121 [==============================] - 0s 981us/step - loss: 0.2893\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  41.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7378fa440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd7378fa440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "220/242 [==========================>...] - ETA: 0s - loss: 1.1150"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7378fa560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7378fa560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0698 - val_loss: 0.7257\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 0.6315\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4031\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4004\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.3658\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.4465\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3551\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3576 - val_loss: 0.4744\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3619\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.4411\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3323\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3752\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.4214\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.3379\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.4371\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3276 - val_loss: 0.3248\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3234 - val_loss: 0.4326\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3191\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3186 - val_loss: 0.4486\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3182 - val_loss: 0.3069\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.5131\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3151 - val_loss: 0.3144\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3113 - val_loss: 0.5216\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3140 - val_loss: 0.4175\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.5747\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3522\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3064 - val_loss: 0.3852\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3041 - val_loss: 0.3397\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3835\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2993 - val_loss: 0.3054\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.3103\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2965 - val_loss: 0.2977\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2940 - val_loss: 0.3262\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.3261\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2910 - val_loss: 0.2963\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.4311\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.5142\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.5788\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2906 - val_loss: 0.2996\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2865 - val_loss: 0.3528\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2848 - val_loss: 0.2861\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2823 - val_loss: 0.2998\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2822 - val_loss: 0.2940\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2801 - val_loss: 0.3078\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2792 - val_loss: 0.2814\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2777 - val_loss: 0.3254\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2763 - val_loss: 0.2976\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2761 - val_loss: 0.3066\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.3075\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2746 - val_loss: 0.3776\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2725 - val_loss: 0.2954\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 0.4031\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.2746\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2688 - val_loss: 0.5547\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2728 - val_loss: 0.4049\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2706 - val_loss: 0.4461\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2672 - val_loss: 0.2785\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2667 - val_loss: 0.3832\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2665 - val_loss: 0.3410\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.4374\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2650 - val_loss: 0.2916\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2623 - val_loss: 0.5043\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2639 - val_loss: 0.3292\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3153\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  41.4s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd737993560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd737993560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "223/242 [==========================>...] - ETA: 0s - loss: 0.9394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737bf6f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd737bf6f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9149 - val_loss: 1.1298\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 0.4629\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4891\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.4121\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3654\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3809\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3562 - val_loss: 0.5274\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.6024\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.8120\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.6976\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3371 - val_loss: 0.7951\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.8469\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.9981\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 1.0174\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.8693\n",
            "121/121 [==============================] - 0s 994us/step - loss: 0.3494\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   7.0s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f49200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f49200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "218/242 [==========================>...] - ETA: 0s - loss: 0.8803"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7359d6e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd7359d6e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8495 - val_loss: 1.4991\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 1.5083\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.5970\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 1.0257\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.6075\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4875\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.3333\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3540 - val_loss: 0.3602\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.4214\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3474 - val_loss: 0.3567\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3418 - val_loss: 0.4116\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3268\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3326 - val_loss: 0.3261\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.4203\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3242\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3241 - val_loss: 0.3903\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3172\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3201 - val_loss: 0.3602\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3179 - val_loss: 0.3750\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3152 - val_loss: 0.3807\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3155 - val_loss: 0.3566\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3136 - val_loss: 0.3263\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3111 - val_loss: 0.3704\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3094 - val_loss: 0.3478\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3075\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.3068\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3025 - val_loss: 0.4239\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.4176\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3058 - val_loss: 0.5204\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.3068\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3178\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2975 - val_loss: 0.3463\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 0.3217\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.3471\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2946 - val_loss: 0.3149\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2913 - val_loss: 0.4613\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.2995\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  21.0s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f498c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f498c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "233/242 [===========================>..] - ETA: 0s - loss: 1.2089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd73a7494d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd73a7494d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1852 - val_loss: 3.2153\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5898 - val_loss: 3.0128\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5015 - val_loss: 0.4502\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4378 - val_loss: 0.4035\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.3840\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4242\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.3890\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.4232\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.3928\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4090\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3666\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3624 - val_loss: 0.3608\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.3996\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.4060\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3814\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3833\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3874\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.3828\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3917\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3709\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3684\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.3789\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3641\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  10.7s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f49950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd740f49950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "197/242 [=======================>......] - ETA: 0s - loss: 1.2558"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd73593e680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd73593e680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1439 - val_loss: 0.6455\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5927 - val_loss: 2.4470\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 2.8515\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 1.8737\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 1.0531\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4479\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.3677\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.4098\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.5912\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.5012\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.5537\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.5948\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.7224\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.7971\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.7463\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3543 - val_loss: 0.8203\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3527 - val_loss: 0.7718\n",
            "121/121 [==============================] - 0s 942us/step - loss: 0.3678\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   7.7s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd737bf6cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd737bf6cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "192/242 [======================>.......] - ETA: 0s - loss: 1.0812"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735b5aa70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735b5aa70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 4.0590\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 1.5121\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.4433\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.4748\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.3921\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.4087\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.3755\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3709\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.4033\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.3531\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4519\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3635\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.3578\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3643 - val_loss: 0.4479\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.3444\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.4293\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 0.3393\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3535 - val_loss: 0.3632\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.4213\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3550\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3656\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.3287\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3448\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3609\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3477\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3393\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3697\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.3331\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.5182\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.3217\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3352 - val_loss: 0.3318\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.3749\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3547\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.3486\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.3289\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.4845\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.5741\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.9919\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.6034\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.8060\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3293\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  20.9s\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735ad9ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd735ad9ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "355/363 [============================>.] - ETA: 0s - loss: 0.8327"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e5d4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd735e5d4d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8248 - val_loss: 1.0986\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4342 - val_loss: 1.0546\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3555\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3938\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3613 - val_loss: 0.3393\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3987\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3480 - val_loss: 0.3424\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3424 - val_loss: 0.3257\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3372 - val_loss: 0.3320\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3332 - val_loss: 0.4133\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.5091\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3313 - val_loss: 0.6809\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3270 - val_loss: 0.3064\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.3029\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.3435\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3194 - val_loss: 0.3989\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3180 - val_loss: 0.4374\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.3216\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3126\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3094 - val_loss: 0.4015\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3063 - val_loss: 0.3004\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3039 - val_loss: 0.3567\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3023 - val_loss: 0.3239\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3006 - val_loss: 0.3531\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2995 - val_loss: 0.3617\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2964 - val_loss: 0.4563\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.5255\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.5424\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2962 - val_loss: 0.2938\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2927 - val_loss: 0.4005\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2918 - val_loss: 0.2979\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2879 - val_loss: 0.3546\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 0.2795\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2850 - val_loss: 0.3285\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2840 - val_loss: 0.3484\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2837 - val_loss: 0.2903\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2811 - val_loss: 0.4263\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2794 - val_loss: 0.2882\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2839 - val_loss: 0.5399\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2810 - val_loss: 0.2825\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2799 - val_loss: 0.4988\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2804 - val_loss: 0.2730\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.4292\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2767 - val_loss: 0.2798\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2735 - val_loss: 0.3264\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2741 - val_loss: 0.3611\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2737 - val_loss: 0.6502\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2747 - val_loss: 0.2744\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2701 - val_loss: 0.3091\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2697 - val_loss: 0.3575\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2704 - val_loss: 0.4871\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2689 - val_loss: 0.3053\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd740fb2750>,\n",
              "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
              "                                                          0.02390836445593178,\n",
              "                                                          0.008731907739399206,\n",
              "                                                          0.004725396149933917,\n",
              "                                                          0.0006154014789262348,\n",
              "                                                          0.0006153331256530192,\n",
              "                                                          0.0003920021771415983,\n",
              "                                                          0.01619845322936229,\n",
              "                                                          0.004779156784872302,\n",
              "                                                          0.007821074275112298,...\n",
              "                                                          0.005021425736625637,\n",
              "                                                          0.0005703073595961105,\n",
              "                                                          0.001151888789941251,\n",
              "                                                          0.001621231156394198,\n",
              "                                                          0.0024505367684280487,\n",
              "                                                          0.011155092541719619,\n",
              "                                                          0.0007524347058135697,\n",
              "                                                          0.0032032448128444043,\n",
              "                                                          0.004591455636549438,\n",
              "                                                          0.0003715541189658278, ...],\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14, 15,\n",
              "                                                      16, 17, 18, 19, 20, 21,\n",
              "                                                      22, 23, 24, 25, 26, 27,\n",
              "                                                      28, 29, 30, ...]},\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd63y55_ZjTL",
        "outputId": "03407e9d-8093-4e42-b379-a63502b856dd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.0059640580092043885}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egkpTlC0ZjWC",
        "outputId": "0669eb35-0f71-440d-e07a-bdcc5b8b7f0f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.32139770189921063"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEKtwIaFwoJ1",
        "outputId": "8c9a9564-5fff-4571-a9e9-09edcf14c4fd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 990us/step - loss: 0.2833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2833365499973297"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = rnd_search_cv.best_estimator_.model\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxI1Q-LOwoMW",
        "outputId": "d213be66-0e83-4f40-fb03-f5fd135fde6b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fd740cd85d0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDxNAjiYwoO3",
        "outputId": "ad7a202f-c2b7-4a02-edc3-424c44ab8813"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 900us/step - loss: 0.2833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2833365499973297"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if 훈련에 시간이 많이 걸릴 경우 탐색할 수 있는 하이퍼파라미터 공간에 제약이 생김<br>\n",
        "=> 탐색 과정을 수동으로 보조하여 이 문제를 부분적으로 완화 가능<br>\n",
        "하이퍼파라미터 값의 범위를 크게하여 빠르게 첫 번째 랜덤 탐색을 수행하고, 첫 번째 탐색에서 찾은 최상의 하이퍼파라미터 값을 중심으로 더 좁은 범위 탐색. 이런 방식으로 계속 진행하면 좋은 하이퍼파라미터 집합을 좁혀나갈 수는 있지만 시간이 많이 소요되며 최상의 방법은 아닐 것."
      ],
      "metadata": {
        "id": "ET2l_zhxwyQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "더 효율적으로 하이퍼파라미터 공간을 탐색하는 기법<br>\n",
        "-> 탐색 지역이 좋다고 판명될 때 더 탐색을 수행하는 것 <br>\n",
        "<br>\n",
        "하이퍼파라미터 최적화에 사용할 수 있는 파이썬 라이브러리\n",
        "- Hyperopt: (학습률과 같은 실수와 층의 개수 같은 이산적인 값을 포함하여) 모든 종류의 복잡한 탐색 공간에 대해 최적화를 수행할 수 있는 라이브러리\n",
        "- Hyperas, kopt, Talos: 케라스 모델을 위한 하이퍼파라미터 최적화 라이브러리\n",
        "- 케라스 튜너(Keras Tuner): 사용하기 쉬운 케라스 하이퍼파라미터 최적화 라이브러리\n",
        "- Scikit-Optimize(skopt): 범용 최적화 라이브러리. BayesSearchCV 클래스는 GridSearchCV와 비슷한 인터페이스를 사용하여 베이즈(Bayesian) 최적화를 수행\n",
        "- Spearmint: 베이즈 최적화 라이브러리\n",
        "- Hyperband: 빠른 하이퍼파라미터 튜닝 라이브러리\n",
        "- Sklearn-Deap: GridSearchCV와 비슷한 인터페이스를 가진 진화 알고리즘(evolutionart algorithm) 기반의 하이퍼파라미터 최적화 라이브러리"
      ],
      "metadata": {
        "id": "uLZbHlt5xWmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3.1 은닉층 개수"
      ],
      "metadata": {
        "id": "tXOcMm4EZkhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이론적으로 은닉층이 하나인 다층 퍼셉트론이더라도 뉴런 개수가 충분하면 아주 복잡한 함수도 모델링할 수 있음<br>\n",
        "하지만 복잡한 문제에서는 심층 신경망이 얕은 신경망보다 **파라미터 효율성**(parameter efficiency)이 훨씬 좋음 (-> 심층 신경망은 복잡한 함수를 모델링하는데 얕은 신경망보다 훨씬 적은 수의 뉴런을 사용하므로 동일한 양의 훈련 데이터에서 더 높은 성능을 낼 수 있음)"
      ],
      "metadata": {
        "id": "cOSCd3loZmyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "계층 구조는 심층 신경망이 좋은 솔루션으로 빨리 수렴하게끔 도와줄 뿐만 아니라 새로운 데이터에 일반화되는 능력도 향상시켜줌.<br>\n",
        "새로운 신경망에서 처음 몇 개 층의 가중치와 편향을 난수로 초기화하는 대신 첫 번째 신경망 층에 있는 가중치와 편향값으로 초기화 가능. 이런 방식을 사용하면 대부분의 저수준 구조를 학습할 필요가 없음 => **전이 학습**(transfer learning)"
      ],
      "metadata": {
        "id": "d8kS5KA_Zm0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결론적으로 하나 또는 두 개의 은닉층만으로도 많은 문제를 꽤 잘 해결할 것"
      ],
      "metadata": {
        "id": "sSmxPqoNZm3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3.2 은닉층의 뉴런 개수"
      ],
      "metadata": {
        "id": "jWzsfPxNZm5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력층과 출력층의 뉴런 개수는 해당 작업에 필요한 입력과 출력의 형태에 따라 결정<br>\n",
        "은닉층의 구성 방식은 일반적으로 각 층의 뉴런을 점점 줄여서 깔때기처럼 구성. 저수준의 많은 특성이 고수준의 적은 특성으로 합쳐질 수 있기 때문."
      ],
      "metadata": {
        "id": "GVRTEynIZm8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "네트워크가 과대적합 시작되기 전까지 점진적으로 뉴런 수를 늘릴 수 있음<br>\n",
        "하지만 실전에서는 필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택하고, 그런 다음 과대적합되지 않도록 조기 종료나 규제 기법을 사용하는 것이 간단하고 효과적."
      ],
      "metadata": {
        "id": "AJfp3OpU0cwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 층의 뉴런 수보다 층 수를 늘리는 쪽이 이득이 많음"
      ],
      "metadata": {
        "id": "ueEAaW3e0cyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3.3 학습률, 배치 크기 그리고 다른 하이퍼파라미터"
      ],
      "metadata": {
        "id": "oE69qLdvZnBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습률**<Br>\n",
        "가장 중요한 하이퍼파라미터. 일반적으로 최적의 학습률은 최대 학습률의 절반 정도.<br>\n",
        "좋은 학습률을 찾는 방법은 매우 낮은 학습률에서 시작해서 점진적으로 매우 큰 학습률까지 수백 번 반복하여 모델을 훈련하는 것. "
      ],
      "metadata": {
        "id": "aerEw4kpZnDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer**<br>\n",
        "고전적인 평범한 미니배치 경사 하강법보다 더 좋은 optimizer를 선택하는 것(그리고 이 optimizer의 하이퍼파라미터를 튜닝하는 것)도 매우 중요."
      ],
      "metadata": {
        "id": "WuxfS6MQ08Ik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**배치 크기**<br>\n",
        "배치 크기는 모델 성능과 훈련 시간에 큰 영향을 미칠 수 있음.<br>\n",
        "큰 배치를 사용하는 것의 주요 장점은 GPU와 같은 하드웨어 가속시를 효율적으로 활용가능하다는 점 (-> 훈련 알고리즘이 초당 더 많은 샘플 처리 가능)<br>\n",
        "**주의할 점: 실전에서 큰 배치를 사용하면 특히 훈련 초기에 종종 불안정하게 훈련될 수 있음<br>\n",
        "큰 배치 크기는 일반화 성능에 영향을 미치지 않고 훈련 시간을 매우 단축함<br>\n",
        "따라서 학습률 예열을 사용해 큰 배치 크기를 시도해보고 만약 훈련이 불안정하거나 최종 성능이 만족스럽지 못하다면 작은 배치를 사용하는 방법 이용"
      ],
      "metadata": {
        "id": "ubQN2H6v08NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**활성화 함수**<br>\n",
        "일반적으로 ReLU 활성화 함수가 모든 은닉층에 좋은 기본값.<br>\n",
        "출력층의 활성화 함수는 수행하는 작업에 따라 달라짐"
      ],
      "metadata": {
        "id": "OJOBk9oQ08O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**반복 횟수**<br>\n",
        "대부분의 경우 훈련 반복 횟수는 튜닝할 필요 없음, 대신 조기 종료 사용."
      ],
      "metadata": {
        "id": "f1qIrjbC08Qg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tip) 최적의 학습률은 다른 하이퍼파라미터에 의존적. 특히 배치 크기에 영향을 많이 받음. 따라서 다른 하이퍼파라미터를 수정하면 학습률도 반드시 튜닝해야함."
      ],
      "metadata": {
        "id": "b0jWi5NY08TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X1S_Jk1PjnC",
        "outputId": "0aa12780-9212-4282-f933-b66ad8df884f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to markdown \"/content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKvhCUmWPjpo",
        "outputId": "d84a475f-a8de-4207-8e02-474f1dedc88b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras.ipynb to markdown\n",
            "[NbConvertApp] Support files will be in Ch10_Neural_Nets_with_Keras_files/\n",
            "[NbConvertApp] Making directory /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras_files\n",
            "[NbConvertApp] Making directory /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras_files\n",
            "[NbConvertApp] Making directory /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras_files\n",
            "[NbConvertApp] Making directory /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras_files\n",
            "[NbConvertApp] Making directory /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras_files\n",
            "[NbConvertApp] Writing 324621 bytes to /content/drive/MyDrive/Colab Notebooks/Handson_ML/Ch10_Neural_Nets_with_Keras.md\n"
          ]
        }
      ]
    }
  ]
}